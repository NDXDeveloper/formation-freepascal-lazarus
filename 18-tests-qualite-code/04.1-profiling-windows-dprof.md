üîù Retour au [Sommaire](/SOMMAIRE.md)

# 18.4.1 Profiling Windows (DProf)

## Introduction au Profiling

Le profiling est une technique qui permet d'analyser les performances de votre application en identifiant les parties du code qui consomment le plus de temps d'ex√©cution ou de ressources. C'est un outil essentiel pour optimiser vos programmes.

### Pourquoi faire du profiling ?

- **Identifier les goulots d'√©tranglement** : d√©couvrir quelles fonctions ralentissent votre application
- **Optimiser de mani√®re cibl√©e** : concentrer vos efforts l√† o√π ils auront le plus d'impact
- **Mesurer l'am√©lioration** : v√©rifier que vos optimisations sont efficaces
- **Comprendre le comportement** : voir comment votre code s'ex√©cute r√©ellement

## Qu'est-ce que DProf ?

DProf (Delphi Profiler) est un outil de profiling compatible avec FreePascal sur Windows. Il analyse votre programme pendant son ex√©cution et g√©n√®re un rapport d√©taill√© sur :

- Le temps pass√© dans chaque fonction
- Le nombre d'appels de chaque fonction
- La hi√©rarchie des appels (qui appelle quoi)

## Installation et Configuration

### Pr√©requis

DProf n√©cessite :
- FreePascal/Lazarus install√© sur Windows
- Votre projet doit √™tre compil√© avec des options sp√©ciales
- L'outil DProf.exe (g√©n√©ralement fourni avec certaines distributions ou t√©l√©chargeable s√©par√©ment)

### Configuration du Projet

Pour que votre programme puisse √™tre profil√© avec DProf, vous devez le compiler avec des informations de d√©bogage sp√©ciales.

#### Dans Lazarus IDE

1. Ouvrez votre projet
2. Allez dans **Projet ‚Üí Options du projet**
3. Section **Compilation et liaison** :
   - Cochez **G√©n√©rer les informations de d√©bogage pour GDB**
   - Cochez **Utiliser Heaptrc** (optionnel, pour le suivi m√©moire)

4. Section **Options du compilateur personnalis√©es** :
   Ajoutez ces options :
   ```
   -pg
   ```

#### En ligne de commande

Compilez votre projet avec l'option `-pg` :

```bash
fpc -pg -gl MonProgramme.pas
```

**Explications des options :**
- `-pg` : Active l'instrumentation pour le profiling (g√©n√®re du code suppl√©mentaire qui enregistre les appels)
- `-gl` : Inclut les informations de ligne pour un d√©bogage d√©taill√©

## Utilisation de DProf

### √âtape 1 : Ex√©cuter votre Programme

Une fois compil√© avec `-pg`, ex√©cutez normalement votre programme :

```bash
MonProgramme.exe
```

Pendant l'ex√©cution, le programme g√©n√®re automatiquement un fichier `gmon.out` dans le r√©pertoire courant. Ce fichier contient toutes les donn√©es de profiling brutes.

**Important :** Le fichier `gmon.out` est √©cras√© √† chaque ex√©cution, donc sauvegardez-le si vous voulez comparer plusieurs sessions.

### √âtape 2 : Analyser avec gprof

Sur Windows, vous utilisez `gprof` (GNU Profiler) pour lire le fichier `gmon.out` :

```bash
gprof MonProgramme.exe gmon.out > rapport_profiling.txt
```

Cette commande g√©n√®re un rapport texte lisible.

### √âtape 3 : Analyser avec DProf (interface graphique)

Si vous avez DProf.exe :

```bash
dprof MonProgramme.exe gmon.out
```

DProf ouvre une interface graphique qui affiche :
- La liste des fonctions tri√©es par temps d'ex√©cution
- Des graphiques de r√©partition du temps
- L'arbre d'appels (call graph)

## Comprendre le Rapport de Profiling

### Structure du Rapport gprof

Le rapport gprof contient trois sections principales :

#### 1. Flat Profile (Profil Plat)

```
  %   cumulative   self              self     total
 time   seconds   seconds    calls  ms/call  ms/call  name
 45.20      1.35     1.35   100000     0.01     0.02  CalculComplexe
 23.40      2.05     0.70    50000     0.01     0.01  TrierTableau
 12.70      2.43     0.38   200000     0.00     0.00  RechercherElement
```

**Colonnes expliqu√©es :**

- **% time** : Pourcentage du temps total pass√© dans cette fonction
- **cumulative seconds** : Temps cumul√© depuis le d√©but du rapport
- **self seconds** : Temps pass√© uniquement dans cette fonction (sans les sous-fonctions)
- **calls** : Nombre de fois que la fonction a √©t√© appel√©e
- **self ms/call** : Temps moyen par appel (en millisecondes)
- **total ms/call** : Temps moyen incluant les sous-fonctions
- **name** : Nom de la fonction

#### 2. Call Graph (Graphe d'Appels)

```
index % time    self  children    called     name
[1]    68.3    1.35     0.70  100000/100000      Principal [2]
              0.70     0.00   50000/50000       TrierTableau [3]
-----------------------------------------------
              1.35     0.70  100000/100000      Principal [2]
[2]    68.3    1.35     0.70                   CalculComplexe [1]
              0.70     0.00   50000/50000       TrierTableau [3]
```

Cette section montre :
- **Qui appelle chaque fonction** (parents)
- **Quelles fonctions sont appel√©es** (enfants)
- **La distribution du temps** entre appelants et appel√©s

#### 3. Index des Fonctions

Une liste alphab√©tique de toutes les fonctions avec leur index pour r√©f√©rence crois√©e.

## Interpr√©ter les R√©sultats

### Identifier les Fonctions Critiques

Les fonctions √† optimiser en priorit√© sont celles qui ont :

1. **Un % time √©lev√©** (>10% du temps total)
2. **Un grand nombre d'appels** avec un temps self significatif
3. **Un temps total √©lev√©** m√™me si le temps self est faible (elles appellent des fonctions lentes)

### Exemple d'Analyse

Si vous voyez :

```
 45.20    1.35     1.35   100000     0.01     0.02  CalculComplexe
```

**Interpr√©tation :**
- Cette fonction consomme 45% du temps total d'ex√©cution
- Elle est appel√©e 100 000 fois
- Chaque appel prend en moyenne 0.01 ms
- **Action** : C'est la priorit√© num√©ro 1 pour l'optimisation

Si vous voyez :

```
  2.10    2.50     0.06        1    60.00   2500.00  FonctionPrincipale
```

**Interpr√©tation :**
- Cette fonction ne prend que 2% du temps directement
- Mais le temps total incluant les sous-fonctions est de 2500 ms
- Elle est appel√©e une seule fois
- **Action** : Le probl√®me vient des fonctions qu'elle appelle, pas d'elle-m√™me

## Optimisations Courantes

### 1. R√©duire le Nombre d'Appels

Si une fonction est appel√©e tr√®s fr√©quemment avec un temps faible :

**Avant :**
```pascal
for i := 1 to 10000 do
begin
  valeur := ObtenirConfiguration('cle'); // Appel√© 10000 fois
  Traiter(valeur);
end;
```

**Apr√®s :**
```pascal
valeur := ObtenirConfiguration('cle'); // Appel√© 1 fois
for i := 1 to 10000 do
begin
  Traiter(valeur);
end;
```

### 2. Optimiser les Algorithmes

Si une fonction a un temps self √©lev√©, am√©liorez son algorithme :

**Avant (O(n¬≤)) :**
```pascal
function Rechercher(tableau: array of Integer; valeur: Integer): Integer;
var
  i: Integer;
begin
  for i := 0 to High(tableau) do
    if tableau[i] = valeur then
      Exit(i);
  Result := -1;
end;
```

**Apr√®s (utiliser une structure appropri√©e) :**
```pascal
// Utiliser un TDictionary pour O(1) au lieu de O(n)
var
  dictionnaire: TDictionary<Integer, Integer>;
```

### 3. Mise en Cache

Si une fonction calcule souvent la m√™me chose :

```pascal
var
  CacheResultats: TDictionary<string, Integer>;

function CalculCouteux(parametre: string): Integer;
begin
  if CacheResultats.ContainsKey(parametre) then
    Exit(CacheResultats[parametre]); // Retour imm√©diat

  // Calcul complexe uniquement si pas en cache
  Result := FaireCalculComplexe(parametre);
  CacheResultats.Add(parametre, Result);
end;
```

## Conseils et Bonnes Pratiques

### 1. Profilez le Code R√©el

- Utilisez des donn√©es r√©alistes, pas des donn√©es de test minimales
- Profilez le sc√©nario d'utilisation typique de votre application
- Ex√©cutez suffisamment longtemps pour obtenir des statistiques significatives

### 2. Profilez en Mode Release

Compilez avec optimisations activ√©es (`-O2` ou `-O3`) pour profiler le code tel qu'il sera en production :

```bash
fpc -pg -O2 MonProgramme.pas
```

### 3. Concentrez-vous sur les 20%

La r√®gle des 80/20 s'applique : g√©n√©ralement 20% du code consomme 80% du temps. Concentrez-vous sur ces 20%.

### 4. Mesurez Avant et Apr√®s

Toujours profiler avant et apr√®s une optimisation pour v√©rifier son efficacit√© :

```bash
# Avant optimisation
gprof MonProgramme.exe gmon.out > avant.txt

# Apr√®s optimisation
gprof MonProgramme.exe gmon.out > apres.txt

# Comparer les deux fichiers
```

### 5. Attention aux Effets de Bord

Le profiling lui-m√™me ajoute de l'overhead (surco√ªt). Le code avec `-pg` est environ 10-20% plus lent que le code normal. C'est normal, les temps relatifs restent corrects.

## Limitations de DProf/gprof

### Ce que gprof ne fait pas

- **Profiling de la m√©moire** : gprof mesure uniquement le temps CPU, pas l'utilisation m√©moire
- **Profiling multi-thread** : les r√©sultats peuvent √™tre impr√©cis pour les applications multi-thread√©es
- **Profiling temps r√©el** : gprof compte les √©chantillons CPU, pas le temps r√©el (temps d'attente I/O non compt√©)

### Alternatives sur Windows

Pour des besoins avanc√©s :

- **Valgrind** (via WSL) : profiling m√©moire et cache
- **Intel VTune** : profiling tr√®s d√©taill√© (commercial)
- **Very Sleepy** : profiler simple et gratuit pour Windows
- **AQtime** : profiler commercial avec interface graphique avanc√©e

## Workflow Complet d'Optimisation

1. **Identifier le probl√®me** : "Mon programme est lent"
2. **Profiler** : Compiler avec `-pg` et ex√©cuter
3. **Analyser** : Identifier les fonctions critiques avec gprof
4. **Optimiser** : Am√©liorer le code des fonctions identifi√©es
5. **Re-profiler** : V√©rifier l'am√©lioration
6. **R√©p√©ter** : Continuer jusqu'√† atteindre les performances souhait√©es

## Exemple Complet

### Code √† profiler

```pascal
program ExempleProfilage;

{$mode objfpc}{$H+}

uses
  SysUtils;

function Fibonacci(n: Integer): Int64;
begin
  if n <= 1 then
    Exit(n)
  else
    Result := Fibonacci(n-1) + Fibonacci(n-2);
end;

function FibonacciOptimise(n: Integer): Int64;
var
  a, b, i: Int64;
begin
  if n <= 1 then Exit(n);
  a := 0;
  b := 1;
  for i := 2 to n do
  begin
    Result := a + b;
    a := b;
    b := Result;
  end;
end;

var
  i: Integer;
  debut, fin: TDateTime;
begin
  WriteLn('Test Fibonacci r√©cursif...');
  debut := Now;
  for i := 1 to 35 do
    Fibonacci(i);
  fin := Now;
  WriteLn('Temps: ', MilliSecondsBetween(fin, debut), ' ms');

  WriteLn('Test Fibonacci optimis√©...');
  debut := Now;
  for i := 1 to 35 do
    FibonacciOptimise(i);
  fin := Now;
  WriteLn('Temps: ', MilliSecondsBetween(fin, debut), ' ms');
end.
```

### Compilation et Profiling

```bash
# Compiler avec profiling
fpc -pg -gl ExempleProfilage.pas

# Ex√©cuter
ExempleProfilage.exe

# Analyser
gprof ExempleProfilage.exe gmon.out > rapport.txt
```

### R√©sultat Attendu

Le rapport montrera clairement que `Fibonacci` consomme beaucoup plus de temps que `FibonacciOptimise`, d√©montrant l'importance de l'algorithme choisi.

## Conclusion

Le profiling avec DProf/gprof sur Windows est un outil puissant mais simple pour :

- **Mesurer objectivement** les performances
- **Identifier pr√©cis√©ment** les probl√®mes
- **Guider intelligemment** vos optimisations

N'optimisez jamais √† l'aveugle : mesurez d'abord, optimisez ensuite, et mesurez √† nouveau pour confirmer l'am√©lioration.

**R√®gle d'or :** "On n'optimise pas ce qu'on ne mesure pas !"

‚è≠Ô∏è [Profiling Linux (gprof, Valgrind)](/18-tests-qualite-code/04.2-profiling-linux-gprof-valgrind.md)
