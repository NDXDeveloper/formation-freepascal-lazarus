üîù Retour au [Sommaire](/SOMMAIRE.md)

# 22.12 Disaster recovery

## Introduction au disaster recovery

### Qu'est-ce que le disaster recovery ?

Le **disaster recovery** (plan de reprise apr√®s sinistre) est l'ensemble des strat√©gies, proc√©dures et outils qui permettent de restaurer votre application et vos donn√©es apr√®s un incident majeur.

**L'analogie de l'incendie** :

Imaginez que votre maison prend feu. Vous avez plusieurs niveaux de protection :
1. **Pr√©vention** : D√©tecteurs de fum√©e, extincteurs (monitoring, alertes)
2. **Copies de sauvegarde** : Photos de famille dans un coffre-fort ailleurs (backups)
3. **Assurance** : Pour reconstruire si tout est perdu (plan de reprise)
4. **Plan d'√©vacuation** : O√π aller, qui appeler, quoi faire (proc√©dures document√©es)

Le disaster recovery, c'est exactement √ßa pour votre application FreePascal !

### Types de sinistres

**Incidents mat√©riels** :
- üíæ Panne de disque dur
- üî• Incendie dans le datacenter
- ‚ö° Panne √©lectrique prolong√©e
- üåä Inondation

**Incidents logiciels** :
- üêõ Bug critique qui corrompt les donn√©es
- üö´ D√©ploiement rat√©
- üîê Attaque de ransomware
- üóëÔ∏è Suppression accidentelle

**Incidents humains** :
- üë§ Employ√© m√©content
- ü§¶ Erreur de manipulation
- üìù Mauvaise commande SQL (DROP TABLE)

**Incidents externes** :
- ‚òÅÔ∏è Panne du fournisseur cloud
- üåê Probl√®me r√©seau global
- üèõÔ∏è Catastrophe naturelle

### M√©triques cl√©s

#### RTO (Recovery Time Objective)

**D√©finition** : Temps maximum acceptable avant que l'application soit de nouveau fonctionnelle.

**Exemples** :
- Application critique bancaire : RTO = 1 heure
- Site e-commerce : RTO = 4 heures
- Application interne : RTO = 24 heures

#### RPO (Recovery Point Objective)

**D√©finition** : Quantit√© de donn√©es maximale qu'on peut se permettre de perdre (en temps).

**Exemples** :
- Transactions financi√®res : RPO = 0 (aucune perte)
- Application de vente : RPO = 15 minutes
- Blog : RPO = 24 heures

```
    Derni√®re sauvegarde          Incident
           ‚Üì                        ‚Üì
    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚óè‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄX‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí Temps
           ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ RPO ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí
                                    ‚Üê‚îÄ RTO ‚îÄ‚Üí
                                             ‚Üì
                                         R√©cup√©ration
```

**Illustration** :
- **RPO = 1 heure** : Vous perdez au maximum 1 heure de donn√©es
- **RTO = 2 heures** : Votre syst√®me est de nouveau op√©rationnel en 2 heures maximum

### Niveaux de disaster recovery (Tiers)

**Tier 0 - Aucune reprise** :
- Pas de backup
- Reconstruction manuelle
- RTO/RPO = plusieurs jours

**Tier 1 - Backup et restauration** :
- Sauvegardes r√©guli√®res
- Restauration manuelle
- RTO = 24-72 heures
- RPO = heures √† jours

**Tier 2 - Site de secours froid** :
- Infrastructure de secours non d√©marr√©e
- RTO = 12-24 heures
- RPO = heures

**Tier 3 - Site de secours chaud** :
- Infrastructure de secours pr√™te
- RTO = quelques heures
- RPO = minutes √† heures

**Tier 4 - Site miroir actif-actif** :
- Deux sites actifs simultan√©ment
- RTO = minutes
- RPO = secondes √† minutes

## Strat√©gie de sauvegarde

### R√®gle 3-2-1

**Principe fondamental** :
- **3** copies de vos donn√©es
- Sur **2** types de supports diff√©rents
- **1** copie hors site (offsite)

**Exemple pour une application FreePascal** :
```
Copie 1 : Base de donn√©es en production (serveur principal)
Copie 2 : Backup quotidien sur disque externe dans le datacenter
Copie 3 : Backup dans le cloud (AWS S3, Azure Blob, autre datacenter)
```

### Types de sauvegardes

#### 1. Sauvegarde compl√®te (Full Backup)

**Principe** : Copie int√©grale de toutes les donn√©es.

**Avantages** :
- ‚úÖ Restauration simple et rapide
- ‚úÖ Un seul fichier √† restaurer

**Inconv√©nients** :
- ‚ùå Prend beaucoup d'espace
- ‚ùå Longue dur√©e de sauvegarde

**Fr√©quence recommand√©e** : Hebdomadaire

#### 2. Sauvegarde incr√©mentale (Incremental Backup)

**Principe** : Sauvegarde uniquement ce qui a chang√© depuis la **derni√®re sauvegarde** (compl√®te ou incr√©mentale).

**Avantages** :
- ‚úÖ Rapide
- ‚úÖ Peu d'espace disque

**Inconv√©nients** :
- ‚ùå Restauration plus complexe (besoin de tous les incr√©ments)

**Fr√©quence recommand√©e** : Quotidienne

#### 3. Sauvegarde diff√©rentielle (Differential Backup)

**Principe** : Sauvegarde ce qui a chang√© depuis la **derni√®re sauvegarde compl√®te**.

**Avantages** :
- ‚úÖ Restauration plus simple qu'incr√©mentale
- ‚úÖ Plus rapide que compl√®te

**Inconv√©nients** :
- ‚ùå Taille augmente jusqu'√† la prochaine compl√®te

**Fr√©quence recommand√©e** : Quotidienne

### Sch√©ma de sauvegarde complet

```
Dimanche    : Full Backup         (100 GB)
Lundi       : Incremental         (5 GB)   - depuis Dimanche
Mardi       : Incremental         (3 GB)   - depuis Lundi
Mercredi    : Incremental         (4 GB)   - depuis Mardi
Jeudi       : Incremental         (6 GB)   - depuis Mercredi
Vendredi    : Incremental         (8 GB)   - depuis Jeudi
Samedi      : Incremental         (2 GB)   - depuis Vendredi
Dimanche    : Full Backup         (100 GB)
```

**Pour restaurer Vendredi** :
- Restaurer Full Backup (Dimanche)
- Appliquer tous les incr√©ments (Lundi ‚Üí Vendredi)

## Sauvegarde de base de donn√©es

### PostgreSQL

#### Script de backup automatique

```bash
#!/bin/bash
# backup-postgres.sh - Sauvegarde PostgreSQL

# Configuration
DB_NAME="myappdb"
DB_USER="postgres"
BACKUP_DIR="/backups/postgres"
RETENTION_DAYS=30
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="${BACKUP_DIR}/${DB_NAME}_${DATE}.sql.gz"

# Cr√©er le r√©pertoire si n√©cessaire
mkdir -p "$BACKUP_DIR"

# Effectuer le backup avec compression
echo "[$(date)] D√©but du backup de $DB_NAME..."
pg_dump -U "$DB_USER" -h localhost "$DB_NAME" | gzip > "$BACKUP_FILE"

if [ $? -eq 0 ]; then
    echo "[$(date)] ‚úì Backup cr√©√©: $BACKUP_FILE"

    # Taille du fichier
    SIZE=$(du -h "$BACKUP_FILE" | cut -f1)
    echo "[$(date)] Taille: $SIZE"

    # V√©rifier l'int√©grit√©
    if gzip -t "$BACKUP_FILE"; then
        echo "[$(date)] ‚úì Int√©grit√© v√©rifi√©e"
    else
        echo "[$(date)] ‚úó Erreur d'int√©grit√©!"
        exit 1
    fi

    # Supprimer les anciens backups
    find "$BACKUP_DIR" -name "${DB_NAME}_*.sql.gz" -mtime +$RETENTION_DAYS -delete
    echo "[$(date)] ‚úì Anciens backups supprim√©s (>$RETENTION_DAYS jours)"

    # Upload vers le cloud (optionnel)
    # aws s3 cp "$BACKUP_FILE" s3://my-backups/postgres/

else
    echo "[$(date)] ‚úó √âchec du backup!"
    exit 1
fi

echo "[$(date)] Backup termin√©"
```

**Configurer la t√¢che cron** :

```bash
# √âditer crontab
crontab -e

# Ajouter (backup quotidien √† 2h du matin)
0 2 * * * /path/to/backup-postgres.sh >> /var/log/backup-postgres.log 2>&1
```

#### Restauration PostgreSQL

```bash
#!/bin/bash
# restore-postgres.sh - Restauration PostgreSQL

DB_NAME="myappdb"
DB_USER="postgres"
BACKUP_FILE="$1"

if [ -z "$BACKUP_FILE" ]; then
    echo "Usage: $0 <backup_file.sql.gz>"
    exit 1
fi

if [ ! -f "$BACKUP_FILE" ]; then
    echo "‚úó Fichier non trouv√©: $BACKUP_FILE"
    exit 1
fi

echo "‚ö†Ô∏è  ATTENTION: Cette op√©ration va √©craser la base de donn√©es $DB_NAME"
read -p "Continuer? (oui/non): " CONFIRM

if [ "$CONFIRM" != "oui" ]; then
    echo "Annul√©"
    exit 0
fi

echo "[$(date)] Arr√™t des connexions..."
psql -U "$DB_USER" -c "SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE datname = '$DB_NAME';"

echo "[$(date)] Suppression de l'ancienne base..."
dropdb -U "$DB_USER" "$DB_NAME"

echo "[$(date)] Cr√©ation de la nouvelle base..."
createdb -U "$DB_USER" "$DB_NAME"

echo "[$(date)] Restauration depuis $BACKUP_FILE..."
gunzip -c "$BACKUP_FILE" | psql -U "$DB_USER" "$DB_NAME"

if [ $? -eq 0 ]; then
    echo "[$(date)] ‚úì Restauration r√©ussie"
else
    echo "[$(date)] ‚úó √âchec de la restauration"
    exit 1
fi
```

### MySQL/MariaDB

#### Backup MySQL

```bash
#!/bin/bash
# backup-mysql.sh

DB_NAME="myappdb"
DB_USER="root"
DB_PASSWORD="password"
BACKUP_DIR="/backups/mysql"
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="${BACKUP_DIR}/${DB_NAME}_${DATE}.sql.gz"

mkdir -p "$BACKUP_DIR"

mysqldump -u "$DB_USER" -p"$DB_PASSWORD" \
    --single-transaction \
    --routines \
    --triggers \
    --events \
    "$DB_NAME" | gzip > "$BACKUP_FILE"

if [ $? -eq 0 ]; then
    echo "‚úì Backup cr√©√©: $BACKUP_FILE"
else
    echo "‚úó √âchec du backup"
    exit 1
fi
```

#### Restauration MySQL

```bash
#!/bin/bash
# restore-mysql.sh

DB_NAME="myappdb"
DB_USER="root"
DB_PASSWORD="password"
BACKUP_FILE="$1"

if [ -z "$BACKUP_FILE" ]; then
    echo "Usage: $0 <backup_file.sql.gz>"
    exit 1
fi

gunzip -c "$BACKUP_FILE" | mysql -u "$DB_USER" -p"$DB_PASSWORD" "$DB_NAME"

if [ $? -eq 0 ]; then
    echo "‚úì Restauration r√©ussie"
else
    echo "‚úó √âchec de la restauration"
    exit 1
fi
```

### SQLite

#### Backup SQLite depuis FreePascal

```pascal
unit SQLiteBackup;

{$mode objfpc}{$H+}

interface

uses
  Classes, SysUtils, SQLite3Conn, SQLDB;

type
  TSQLiteBackupManager = class
  private
    FConnection: TSQLite3Connection;
    FBackupDir: string;
    FRetentionDays: Integer;
  public
    constructor Create(AConnection: TSQLite3Connection; const ABackupDir: string);

    function CreateBackup: string;
    function RestoreBackup(const BackupFile: string): Boolean;
    procedure CleanOldBackups;
    function VerifyBackup(const BackupFile: string): Boolean;

    property RetentionDays: Integer read FRetentionDays write FRetentionDays;
  end;

implementation

uses
  DateUtils, FileUtil;

constructor TSQLiteBackupManager.Create(AConnection: TSQLite3Connection;
                                       const ABackupDir: string);
begin
  FConnection := AConnection;
  FBackupDir := ABackupDir;
  FRetentionDays := 30;

  // Cr√©er le r√©pertoire de backup si n√©cessaire
  if not DirectoryExists(FBackupDir) then
    ForceDirectories(FBackupDir);
end;

function TSQLiteBackupManager.CreateBackup: string;
var
  SourceFile, BackupFile: string;
  Timestamp: string;
begin
  SourceFile := FConnection.DatabaseName;
  Timestamp := FormatDateTime('yyyymmdd_hhnnss', Now);
  BackupFile := IncludeTrailingPathDelimiter(FBackupDir) +
                'backup_' + Timestamp + '.db';

  try
    // SQLite peut √™tre copi√© directement si ferm√©,
    // sinon utiliser VACUUM INTO ou pg_backup API

    // M√©thode simple : copie de fichier
    if FileExists(SourceFile) then
    begin
      CopyFile(SourceFile, BackupFile);

      // V√©rifier l'int√©grit√©
      if VerifyBackup(BackupFile) then
      begin
        WriteLn('‚úì Backup cr√©√©: ', BackupFile);
        Result := BackupFile;
      end
      else
      begin
        DeleteFile(BackupFile);
        raise Exception.Create('Backup corrompu');
      end;
    end
    else
      raise Exception.Create('Fichier source introuvable');

  except
    on E: Exception do
    begin
      WriteLn('‚úó Erreur de backup: ', E.Message);
      Result := '';
    end;
  end;
end;

function TSQLiteBackupManager.RestoreBackup(const BackupFile: string): Boolean;
var
  TargetFile: string;
begin
  Result := False;

  if not FileExists(BackupFile) then
  begin
    WriteLn('‚úó Fichier de backup introuvable: ', BackupFile);
    Exit;
  end;

  // V√©rifier l'int√©grit√© avant restauration
  if not VerifyBackup(BackupFile) then
  begin
    WriteLn('‚úó Backup corrompu, restauration annul√©e');
    Exit;
  end;

  TargetFile := FConnection.DatabaseName;

  try
    // Fermer la connexion
    if FConnection.Connected then
      FConnection.Close;

    // Sauvegarder l'actuelle (au cas o√π)
    if FileExists(TargetFile) then
      RenameFile(TargetFile, TargetFile + '.before_restore');

    // Copier le backup
    CopyFile(BackupFile, TargetFile);

    // Rouvrir la connexion
    FConnection.Open;

    WriteLn('‚úì Restauration r√©ussie depuis: ', BackupFile);
    Result := True;

  except
    on E: Exception do
    begin
      WriteLn('‚úó Erreur de restauration: ', E.Message);

      // Restaurer l'ancienne version si √©chec
      if FileExists(TargetFile + '.before_restore') then
      begin
        DeleteFile(TargetFile);
        RenameFile(TargetFile + '.before_restore', TargetFile);
      end;
    end;
  end;
end;

procedure TSQLiteBackupManager.CleanOldBackups;
var
  SearchRec: TSearchRec;
  FilePath: string;
  FileAge: TDateTime;
begin
  if FindFirst(IncludeTrailingPathDelimiter(FBackupDir) + 'backup_*.db',
               faAnyFile, SearchRec) = 0 then
  begin
    repeat
      FilePath := IncludeTrailingPathDelimiter(FBackupDir) + SearchRec.Name;
      FileAge := FileDateToDateTime(FileAge(FilePath));

      if DaysBetween(Now, FileAge) > FRetentionDays then
      begin
        DeleteFile(FilePath);
        WriteLn('‚úì Ancien backup supprim√©: ', SearchRec.Name);
      end;
    until FindNext(SearchRec) <> 0;

    FindClose(SearchRec);
  end;
end;

function TSQLiteBackupManager.VerifyBackup(const BackupFile: string): Boolean;
var
  TestConnection: TSQLite3Connection;
  Query: TSQLQuery;
begin
  Result := False;

  TestConnection := TSQLite3Connection.Create(nil);
  Query := TSQLQuery.Create(nil);
  try
    TestConnection.DatabaseName := BackupFile;
    Query.Database := TestConnection;

    try
      TestConnection.Open;

      // V√©rifier l'int√©grit√©
      Query.SQL.Text := 'PRAGMA integrity_check';
      Query.Open;

      Result := (Query.Fields[0].AsString = 'ok');
      Query.Close;

      TestConnection.Close;
    except
      Result := False;
    end;
  finally
    Query.Free;
    TestConnection.Free;
  end;
end;

end.
```

## Sauvegarde des fichiers applicatifs

### Script de backup complet

```bash
#!/bin/bash
# backup-application.sh - Sauvegarde compl√®te de l'application

APP_NAME="myapp"
APP_DIR="/opt/$APP_NAME"
BACKUP_BASE="/backups"
BACKUP_DIR="$BACKUP_BASE/$APP_NAME"
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="$BACKUP_DIR/${APP_NAME}_full_${DATE}.tar.gz"
RETENTION_DAYS=30

# Cr√©er le r√©pertoire
mkdir -p "$BACKUP_DIR"

echo "[$(date)] D√©but du backup complet de $APP_NAME"

# Cr√©er l'archive
tar -czf "$BACKUP_FILE" \
    --exclude='*.log' \
    --exclude='tmp/*' \
    --exclude='cache/*' \
    -C "$(dirname $APP_DIR)" \
    "$(basename $APP_DIR)"

if [ $? -eq 0 ]; then
    SIZE=$(du -h "$BACKUP_FILE" | cut -f1)
    echo "[$(date)] ‚úì Backup cr√©√©: $BACKUP_FILE ($SIZE)"

    # Checksum MD5
    MD5=$(md5sum "$BACKUP_FILE" | cut -d' ' -f1)
    echo "$MD5  $BACKUP_FILE" > "${BACKUP_FILE}.md5"
    echo "[$(date)] ‚úì Checksum MD5: $MD5"

    # Nettoyage des anciens backups
    find "$BACKUP_DIR" -name "${APP_NAME}_full_*.tar.gz" -mtime +$RETENTION_DAYS -delete
    find "$BACKUP_DIR" -name "${APP_NAME}_full_*.md5" -mtime +$RETENTION_DAYS -delete

    # Upload vers le cloud (exemple avec AWS S3)
    if command -v aws &> /dev/null; then
        echo "[$(date)] Upload vers S3..."
        aws s3 cp "$BACKUP_FILE" "s3://my-backups/$APP_NAME/" --storage-class GLACIER
        aws s3 cp "${BACKUP_FILE}.md5" "s3://my-backups/$APP_NAME/"
        echo "[$(date)] ‚úì Upload S3 termin√©"
    fi

    echo "[$(date)] ‚úì Backup termin√© avec succ√®s"
else
    echo "[$(date)] ‚úó √âchec du backup"
    exit 1
fi
```

### Script de restauration

```bash
#!/bin/bash
# restore-application.sh

APP_NAME="myapp"
APP_DIR="/opt/$APP_NAME"
BACKUP_FILE="$1"

if [ -z "$BACKUP_FILE" ]; then
    echo "Usage: $0 <backup_file.tar.gz>"
    exit 1
fi

if [ ! -f "$BACKUP_FILE" ]; then
    echo "‚úó Fichier introuvable: $BACKUP_FILE"
    exit 1
fi

# V√©rifier le checksum
if [ -f "${BACKUP_FILE}.md5" ]; then
    echo "V√©rification du checksum..."
    md5sum -c "${BACKUP_FILE}.md5"

    if [ $? -ne 0 ]; then
        echo "‚úó Checksum invalide! Fichier corrompu?"
        exit 1
    fi
    echo "‚úì Checksum valide"
fi

echo "‚ö†Ô∏è  ATTENTION: Cette op√©ration va √©craser $APP_DIR"
read -p "Continuer? (oui/non): " CONFIRM

if [ "$CONFIRM" != "oui" ]; then
    echo "Annul√©"
    exit 0
fi

# Arr√™ter l'application
echo "Arr√™t de l'application..."
systemctl stop $APP_NAME

# Sauvegarder l'existant
if [ -d "$APP_DIR" ]; then
    echo "Sauvegarde de l'installation actuelle..."
    mv "$APP_DIR" "${APP_DIR}.backup_$(date +%Y%m%d_%H%M%S)"
fi

# Extraire le backup
echo "Extraction du backup..."
tar -xzf "$BACKUP_FILE" -C "$(dirname $APP_DIR)"

if [ $? -eq 0 ]; then
    echo "‚úì Extraction r√©ussie"

    # Red√©marrer l'application
    echo "D√©marrage de l'application..."
    systemctl start $APP_NAME

    # V√©rifier le statut
    sleep 2
    if systemctl is-active --quiet $APP_NAME; then
        echo "‚úì Application d√©marr√©e avec succ√®s"
    else
        echo "‚úó √âchec du d√©marrage"
        exit 1
    fi
else
    echo "‚úó √âchec de l'extraction"
    exit 1
fi
```

## Tests de restauration

### Pourquoi tester les restaurations ?

**Un backup non test√© n'est pas un backup !**

Beaucoup d'entreprises d√©couvrent que leurs backups sont inutilisables au moment critique. Il est essentiel de tester r√©guli√®rement.

### Script de test automatis√©

```bash
#!/bin/bash
# test-backup-restore.sh - Test automatique de backup/restauration

APP_NAME="myapp"
TEST_DIR="/tmp/backup_test_$$"
BACKUP_FILE="$1"
LOG_FILE="/var/log/backup_test.log"

log() {
    echo "[$(date)] $1" | tee -a "$LOG_FILE"
}

cleanup() {
    rm -rf "$TEST_DIR"
}

trap cleanup EXIT

if [ -z "$BACKUP_FILE" ]; then
    log "‚úó Usage: $0 <backup_file>"
    exit 1
fi

log "=== D√©but du test de restauration ==="
log "Backup: $BACKUP_FILE"

# Cr√©er l'environnement de test
mkdir -p "$TEST_DIR"

# Test 1: V√©rifier l'int√©grit√© de l'archive
log "Test 1: Int√©grit√© de l'archive"
if tar -tzf "$BACKUP_FILE" > /dev/null 2>&1; then
    log "‚úì Archive int√®gre"
else
    log "‚úó Archive corrompue"
    exit 1
fi

# Test 2: Extraire dans l'environnement de test
log "Test 2: Extraction"
tar -xzf "$BACKUP_FILE" -C "$TEST_DIR"
if [ $? -eq 0 ]; then
    log "‚úì Extraction r√©ussie"
else
    log "‚úó √âchec de l'extraction"
    exit 1
fi

# Test 3: V√©rifier les fichiers critiques
log "Test 3: Fichiers critiques"
CRITICAL_FILES=(
    "myapp"
    "config.ini"
    "database.db"
)

for file in "${CRITICAL_FILES[@]}"; do
    if [ -e "$TEST_DIR/$APP_NAME/$file" ]; then
        log "‚úì $file pr√©sent"
    else
        log "‚úó $file manquant"
        exit 1
    fi
done

# Test 4: Tester la base de donn√©es
log "Test 4: Base de donn√©es"
if sqlite3 "$TEST_DIR/$APP_NAME/database.db" "PRAGMA integrity_check;" | grep -q "ok"; then
    log "‚úì Base de donn√©es int√®gre"
else
    log "‚úó Base de donn√©es corrompue"
    exit 1
fi

# Test 5: Tester l'ex√©cutable
log "Test 5: Ex√©cutable"
if [ -x "$TEST_DIR/$APP_NAME/myapp" ]; then
    log "‚úì Ex√©cutable valide"

    # Test de d√©marrage (si possible)
    # "$TEST_DIR/$APP_NAME/myapp" --test-config
else
    log "‚úó Ex√©cutable invalide"
    exit 1
fi

log "=== ‚úì Tous les tests r√©ussis ==="
log "Le backup $BACKUP_FILE est restaurable"

# Envoyer un rapport
mail -s "Test de backup r√©ussi - $APP_NAME" admin@example.com < "$LOG_FILE"
```

**Automatiser les tests** :

```bash
# Tester tous les dimanches √† 4h
0 4 * * 0 /usr/local/bin/test-backup-restore.sh /backups/myapp/latest_full.tar.gz
```

## Plan de reprise document√©

### Template de documentation

```markdown
# Plan de Reprise Apr√®s Sinistre (DRP)
## Application: MyFreePascalApp

**Version**: 1.0
**Date**: 2025-10-08
**Responsable**: √âquipe DevOps

---

## 1. Contacts d'urgence

| R√¥le | Nom | T√©l√©phone | Email |
|------|-----|-----------|-------|
| Responsable IT | Jean Dupont | +33 6 XX XX XX XX | jean@example.com |
| DBA | Marie Martin | +33 6 XX XX XX XX | marie@example.com |
| D√©veloppeur Senior | Pierre Durand | +33 6 XX XX XX XX | pierre@example.com |
| Support H√©bergeur | OVH | +33 X XX XX XX XX | support@ovh.com |

## 2. Architecture syst√®me

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Load Balancer ‚îÇ
‚îÇ   (HAProxy)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ         ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îê
‚îÇ App  ‚îÇ   ‚îÇ App  ‚îÇ
‚îÇ  #1  ‚îÇ   ‚îÇ  #2  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ         ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇPostgreSQL‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Redis  ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## 3. Emplacements des backups

| Type | Emplacement | Fr√©quence | R√©tention |
|------|-------------|-----------|-----------|
| Base de donn√©es | /backups/postgres | Quotidien | 30 jours |
| Fichiers app | /backups/app | Quotidien | 30 jours |
| Configuration | /backups/config | Hebdo | 90 jours |
| Backup offsite | S3: s3://backups-dr/ | Quotidien | 90 jours |

## 4. M√©triques

- **RTO**: 4 heures
- **RPO**: 1 heure

## 5. Proc√©dures de reprise

### 5.1 Panne serveur application

**Sympt√¥mes**: Application inaccessible, erreur 502/503

**Proc√©dure**:

1. **V√©rifier le statut**
   ```bash
   systemctl status myapp
   journalctl -u myapp -n 50
   ```

2. **Red√©marrer le service**
   ```bash
   systemctl restart myapp
   ```

3. **Si √©chec**: D√©ployer sur serveur de secours
   ```bash
   ./deploy-to-standby.sh
   ```

4. **Mettre √† jour le DNS/Load Balancer**

**Dur√©e estim√©e**: 15-30 minutes

### 5.2 Corruption de base de donn√©es

**Sympt√¥mes**: Erreurs SQL, donn√©es incoh√©rentes

**Proc√©dure**:

1. **Arr√™ter l'application**
   ```bash
   systemctl stop myapp
   ```

2. **Identifier le dernier backup valide**
   ```bash
   ls -lh /backups/postgres/
   ```

3. **Restaurer la base de donn√©es**
   ```bash
   ./restore-postgres.sh /backups/postgres/myappdb_20251008_020000.sql.gz
   ```

4. **V√©rifier l'int√©grit√©**
   ```bash
   psql -U postgres -d myappdb -c "SELECT COUNT(*) FROM users;"
   ```

5. **Red√©marrer l'application**
   ```bash
   systemctl start myapp
   ```

6. **Tester fonctionnellement**
   - Connexion utilisateur
   - Op√©ration critique (cr√©ation commande)
   - V√©rifier les logs

**Dur√©e estim√©e**: 1-2 heures
**Perte de donn√©es**: Jusqu'√† 1 heure (dernier backup)

### 5.3 Sinistre complet du datacenter

**Sympt√¥mes**: Tout est inaccessible

**Proc√©dure**:

1. **Activer le site de secours**
   ```bash
   ssh backup-server.example.com
   cd /opt/disaster-recovery
   ./activate-standby-site.sh
   ```

2. **Restaurer depuis les backups cloud**
   ```bash
   # T√©l√©charger depuis S3
   aws s3 sync s3://backups-dr/latest/ /restore/

   # Restaurer la base de donn√©es
   ./restore-postgres.sh /restore/database/latest.sql.gz

   # Restaurer l'application
   ./restore-application.sh /restore/app/latest.tar.gz
   ```

3. **Mettre √† jour le DNS**
   ```bash
   # Pointer vers le nouveau serveur
   # IP: 203.0.113.100 (serveur de secours)
   ```

4. **Notifications**
   - √âquipe technique
   - Clients (via status page)
   - Management

**Dur√©e estim√©e**: 4-6 heures
**Perte de donn√©es**: 1-2 heures

### 5.4 Attaque ransomware

**Sympt√¥mes**: Fichiers chiffr√©s, demande de ran√ßon

**Proc√©dure**:

1. **ISOLER IMM√âDIATEMENT**
   ```bash
   # D√©connecter du r√©seau
   ip link set eth0 down

   # Arr√™ter tous les services
   systemctl stop myapp
   systemctl stop postgresql
   ```

2. **NE PAS PAYER LA RAN√áON**

3. **Documenter l'incident**
   - Screenshots de la demande
   - Liste des fichiers affect√©s
   - Chronologie

4. **Contacter les autorit√©s**
   - Police / Gendarmerie
   - ANSSI (FR): www.ssi.gouv.fr

5. **Reconstruire depuis les backups**
   - Utiliser des backups ant√©rieurs √† l'infection
   - Scanner avec antivirus avant restauration

6. **Enqu√™te forensique**
   - Comment l'attaque est-elle arriv√©e?
   - Autres syst√®mes compromis?

**Dur√©e estim√©e**: 1-3 jours
**Impact**: Potentiellement critique

## 6. Post-incident

### Checklist post-restauration

- [ ] Application fonctionne normalement
- [ ] Base de donn√©es int√®gre
- [ ] Utilisateurs peuvent se connecter
- [ ] Transactions test√©es
- [ ] Logs v√©rifi√©s
- [ ] Monitoring actif
- [ ] √âquipe inform√©e
- [ ] Clients notifi√©s

### Rapport post-mortem

√Ä compl√©ter dans les 48h suivant l'incident:

1. **Chronologie des √©v√©nements**
2. **Cause racine**
3. **Impact (utilisateurs, donn√©es, finances)**
4. **Actions correctives**
5. **Am√©liorations du plan**

---

**Derni√®re mise √† jour**: 2025-10-08
**Prochaine r√©vision**: 2026-01-08
```

## Monitoring et alertes

### Surveillance de la sant√© des backups

```pascal
unit BackupMonitor;

{$mode objfpc}{$H+}

interface

uses
  Classes, SysUtils, DateUtils;

type
  TBackupStatus = (bsOK, bsWarning, bsCritical);

  TBackupHealth = record
    Status: TBackupStatus;
    LastBackupTime: TDateTime;
    LastBackupSize: Int64;
    Message: string;
  end;

  TBackupMonitor = class
  private
    FBackupDir: string;
    FExpectedIntervalHours: Integer;
    FMinimumSizeBytes: Int64;

    function GetLatestBackupFile: string;
    function GetFileAge(const FileName: string): TDateTime;
    function GetFileSize(const FileName: string): Int64;
  public
    constructor Create(const BackupDir: string);

    function CheckHealth: TBackupHealth;
    procedure SendAlert(const Health: TBackupHealth);

    property ExpectedIntervalHours: Integer read FExpectedIntervalHours write FExpectedIntervalHours;
    property MinimumSizeBytes: Int64 read FMinimumSizeBytes write FMinimumSizeBytes;
  end;

implementation

uses
  Process;

constructor TBackupMonitor.Create(const BackupDir: string);
begin
  FBackupDir := BackupDir;
  FExpectedIntervalHours := 24; // 1 backup par jour attendu
  FMinimumSizeBytes := 1024 * 1024; // 1 MB minimum
end;

function TBackupMonitor.GetLatestBackupFile: string;
var
  SearchRec: TSearchRec;
  LatestFile: string;
  LatestTime: TDateTime;
  CurrentTime: TDateTime;
begin
  Result := '';
  LatestTime := 0;

  if FindFirst(IncludeTrailingPathDelimiter(FBackupDir) + '*.sql.gz',
               faAnyFile, SearchRec) = 0 then
  begin
    repeat
      CurrentTime := FileDateToDateTime(SearchRec.Time);
      if CurrentTime > LatestTime then
      begin
        LatestTime := CurrentTime;
        LatestFile := SearchRec.Name;
      end;
    until FindNext(SearchRec) <> 0;

    FindClose(SearchRec);
  end;

  if LatestFile <> '' then
    Result := IncludeTrailingPathDelimiter(FBackupDir) + LatestFile;
end;

function TBackupMonitor.GetFileAge(const FileName: string): TDateTime;
var
  Age: LongInt;
begin
  Age := FileAge(FileName);
  if Age <> -1 then
    Result := FileDateToDateTime(Age)
  else
    Result := 0;
end;

function TBackupMonitor.GetFileSize(const FileName: string): Int64;
var
  SearchRec: TSearchRec;
begin
  Result := 0;
  if FindFirst(FileName, faAnyFile, SearchRec) = 0 then
  begin
    Result := SearchRec.Size;
    FindClose(SearchRec);
  end;
end;

function TBackupMonitor.CheckHealth: TBackupHealth;
var
  LatestBackup: string;
  HoursSinceBackup: Int64;
begin
  Result.Status := bsOK;
  Result.Message := 'Backup OK';

  LatestBackup := GetLatestBackupFile;

  if LatestBackup = '' then
  begin
    Result.Status := bsCritical;
    Result.Message := 'Aucun backup trouv√©!';
    Result.LastBackupTime := 0;
    Result.LastBackupSize := 0;
    Exit;
  end;

  Result.LastBackupTime := GetFileAge(LatestBackup);
  Result.LastBackupSize := GetFileSize(LatestBackup);

  // V√©rifier l'√¢ge
  HoursSinceBackup := HoursBetween(Now, Result.LastBackupTime);

  if HoursSinceBackup > (FExpectedIntervalHours * 2) then
  begin
    Result.Status := bsCritical;
    Result.Message := Format('Dernier backup il y a %d heures (critique)', [HoursSinceBackup]);
  end
  else if HoursSinceBackup > FExpectedIntervalHours then
  begin
    Result.Status := bsWarning;
    Result.Message := Format('Dernier backup il y a %d heures (attention)', [HoursSinceBackup]);
  end;

  // V√©rifier la taille
  if Result.LastBackupSize < FMinimumSizeBytes then
  begin
    Result.Status := bsCritical;
    Result.Message := Format('Taille du backup suspecte: %d bytes', [Result.LastBackupSize]);
  end;
end;

procedure TBackupMonitor.SendAlert(const Health: TBackupHealth);
var
  AProcess: TProcess;
  Subject, Body: string;
begin
  if Health.Status = bsOK then
    Exit;

  Subject := 'Alerte Backup - ' +
             case Health.Status of
               bsWarning: 'WARNING';
               bsCritical: 'CRITICAL';
               else 'UNKNOWN';
             end;

  Body := Format(
    'Status: %s' + LineEnding +
    'Message: %s' + LineEnding +
    'Dernier backup: %s' + LineEnding +
    'Taille: %d bytes',
    [Subject, Health.Message,
     FormatDateTime('yyyy-mm-dd hh:nn:ss', Health.LastBackupTime),
     Health.LastBackupSize]
  );

  // Envoyer par email (exemple simple)
  AProcess := TProcess.Create(nil);
  try
    AProcess.Executable := 'mail';
    AProcess.Parameters.Add('-s');
    AProcess.Parameters.Add(Subject);
    AProcess.Parameters.Add('admin@example.com');
    AProcess.Options := [poWaitOnExit, poUsePipes];

    AProcess.Execute;
    AProcess.Input.Write(Body[1], Length(Body));
    AProcess.CloseInput;
  finally
    AProcess.Free;
  end;
end;

end.
```

### Script de monitoring automatis√©

```bash
#!/bin/bash
# monitor-backups.sh - Surveillance des backups

BACKUP_DIR="/backups"
MAX_AGE_HOURS=25  # Alerte si pas de backup depuis 25h
MIN_SIZE_MB=10    # Taille minimum attendue
EMAIL="admin@example.com"
SLACK_WEBHOOK="https://hooks.slack.com/services/YOUR/WEBHOOK/URL"

check_backup() {
    local backup_type=$1
    local backup_pattern=$2
    local max_age=$3

    echo "V√©rification: $backup_type"

    # Trouver le dernier backup
    latest=$(find "$BACKUP_DIR" -name "$backup_pattern" -type f -printf '%T@ %p\n' | sort -rn | head -1)

    if [ -z "$latest" ]; then
        alert "CRITICAL" "$backup_type" "Aucun backup trouv√©!"
        return 1
    fi

    latest_file=$(echo "$latest" | cut -d' ' -f2)
    latest_time=$(echo "$latest" | cut -d' ' -f1)
    current_time=$(date +%s)
    age_hours=$(( (current_time - ${latest_time%.*}) / 3600 ))

    # V√©rifier l'√¢ge
    if [ $age_hours -gt $max_age ]; then
        alert "WARNING" "$backup_type" "Dernier backup il y a ${age_hours}h"
        return 1
    fi

    # V√©rifier la taille
    size_mb=$(du -m "$latest_file" | cut -f1)
    if [ $size_mb -lt $MIN_SIZE_MB ]; then
        alert "CRITICAL" "$backup_type" "Taille suspecte: ${size_mb}MB"
        return 1
    fi

    echo "‚úì $backup_type OK (${age_hours}h, ${size_mb}MB)"
    return 0
}

alert() {
    local severity=$1
    local backup_type=$2
    local message=$3

    # Email
    echo "$message" | mail -s "[$severity] Backup Alert: $backup_type" "$EMAIL"

    # Slack
    if [ -n "$SLACK_WEBHOOK" ]; then
        curl -X POST "$SLACK_WEBHOOK" \
            -H 'Content-Type: application/json' \
            -d "{\"text\":\"üö® [$severity] Backup Alert: $backup_type\n$message\"}"
    fi

    # Syslog
    logger -t backup-monitor -p user.err "[$severity] $backup_type: $message"
}

# V√©rifier diff√©rents types de backups
check_backup "PostgreSQL" "myappdb_*.sql.gz" $MAX_AGE_HOURS
check_backup "Application" "myapp_full_*.tar.gz" $MAX_AGE_HOURS
check_backup "Configuration" "config_*.tar.gz" 168  # 1 semaine

echo "Monitoring termin√©"
```

**Automatiser avec cron** :

```bash
# V√©rifier toutes les 6 heures
0 */6 * * * /usr/local/bin/monitor-backups.sh >> /var/log/backup-monitor.log 2>&1
```

## Haute disponibilit√© (HA)

### Configuration Master-Slave PostgreSQL

#### Sur le serveur Master (principal)

**1. Configurer PostgreSQL pour la r√©plication** :

```bash
# √âditer postgresql.conf
sudo nano /etc/postgresql/15/main/postgresql.conf
```

```ini
# postgresql.conf
listen_addresses = '*'
wal_level = replica
max_wal_senders = 3
wal_keep_size = 64
hot_standby = on
```

**2. Autoriser la connexion du slave** :

```bash
# √âditer pg_hba.conf
sudo nano /etc/postgresql/15/main/pg_hba.conf
```

```
# pg_hba.conf
# TYPE  DATABASE        USER            ADDRESS                 METHOD
host    replication     replicator      192.168.1.101/32        md5
```

**3. Cr√©er l'utilisateur de r√©plication** :

```sql
CREATE USER replicator WITH REPLICATION ENCRYPTED PASSWORD 'secret_password';
```

**4. Red√©marrer PostgreSQL** :

```bash
sudo systemctl restart postgresql
```

#### Sur le serveur Slave (r√©plique)

**1. Arr√™ter PostgreSQL** :

```bash
sudo systemctl stop postgresql
```

**2. Supprimer les donn√©es existantes** :

```bash
sudo rm -rf /var/lib/postgresql/15/main/*
```

**3. Copier les donn√©es depuis le master** :

```bash
sudo -u postgres pg_basebackup \
    -h 192.168.1.100 \
    -D /var/lib/postgresql/15/main \
    -U replicator \
    -P \
    -v \
    -R \
    -X stream \
    -C -S replica_1
```

**4. D√©marrer PostgreSQL** :

```bash
sudo systemctl start postgresql
```

**5. V√©rifier le statut** :

Sur le **Master** :
```sql
SELECT * FROM pg_stat_replication;
```

Sur le **Slave** :
```sql
SELECT * FROM pg_stat_wal_receiver;
```

### Script de basculement automatique (Failover)

```bash
#!/bin/bash
# failover.sh - Bascule du slave en master

SLAVE_HOST="192.168.1.101"
MASTER_HOST="192.168.1.100"
APP_SERVERS=("app1.example.com" "app2.example.com")

echo "=== Proc√©dure de failover ==="
echo "Master actuel: $MASTER_HOST"
echo "Nouveau master: $SLAVE_HOST"
echo

read -p "Continuer? (oui/non): " CONFIRM
if [ "$CONFIRM" != "oui" ]; then
    echo "Annul√©"
    exit 0
fi

# 1. Promouvoir le slave en master
echo "1. Promotion du slave en master..."
ssh postgres@$SLAVE_HOST "pg_ctl promote -D /var/lib/postgresql/15/main"

if [ $? -eq 0 ]; then
    echo "‚úì Slave promu en master"
else
    echo "‚úó √âchec de la promotion"
    exit 1
fi

# 2. Attendre que le nouveau master soit pr√™t
echo "2. Attente de la disponibilit√© du nouveau master..."
sleep 5

for i in {1..30}; do
    if psql -h $SLAVE_HOST -U postgres -c "SELECT 1" > /dev/null 2>&1; then
        echo "‚úì Nouveau master op√©rationnel"
        break
    fi
    sleep 1
done

# 3. Reconfigurer les serveurs applicatifs
echo "3. Reconfiguration des serveurs applicatifs..."
for server in "${APP_SERVERS[@]}"; do
    echo "   Reconfiguration de $server..."
    ssh root@$server "sed -i 's/$MASTER_HOST/$SLAVE_HOST/g' /opt/myapp/config.ini"
    ssh root@$server "systemctl restart myapp"

    if [ $? -eq 0 ]; then
        echo "   ‚úì $server reconfigur√©"
    else
        echo "   ‚úó √âchec pour $server"
    fi
done

# 4. Mettre √† jour le DNS (si applicable)
echo "4. Mise √† jour DNS..."
# Ajouter votre logique de mise √† jour DNS ici

echo "=== Failover termin√© ==="
echo "Nouveau master: $SLAVE_HOST"
echo "Ancien master: $MASTER_HOST (√† reconfigurer en slave)"
```

### Supervision avec un script de healthcheck

```bash
#!/bin/bash
# db-healthcheck.sh - V√©rification de sant√© de la base de donn√©es

DB_HOST="localhost"
DB_USER="postgres"
DB_NAME="myappdb"
TIMEOUT=5

# Test de connexion
if timeout $TIMEOUT psql -h $DB_HOST -U $DB_USER -d $DB_NAME -c "SELECT 1" > /dev/null 2>&1; then
    echo "‚úì Base de donn√©es accessible"
    exit 0
else
    echo "‚úó Base de donn√©es inaccessible"

    # D√©clencher le failover automatique
    /usr/local/bin/failover.sh

    exit 1
fi
```

**Configurer avec cron pour v√©rifier toutes les minutes** :

```bash
* * * * * /usr/local/bin/db-healthcheck.sh >> /var/log/db-healthcheck.log 2>&1
```

## Outils de disaster recovery

### Bacula - Solution de backup entreprise

**Installation sur Ubuntu** :

```bash
# Installer Bacula
sudo apt update
sudo apt install bacula-server bacula-client bacula-console

# Configurer
sudo nano /etc/bacula/bacula-dir.conf
```

**Configuration de base** :

```
# bacula-dir.conf
Director {
  Name = myapp-dir
  DIRport = 9101
  QueryFile = "/etc/bacula/query.sql"
  WorkingDirectory = "/var/lib/bacula"
  PidDirectory = "/var/run/bacula"
  Maximum Concurrent Jobs = 20
  Password = "director_password"
  Messages = Daemon
}

Job {
  Name = "BackupMyApp"
  Type = Backup
  Level = Incremental
  Client = myapp-client
  FileSet = "MyApp Files"
  Schedule = "WeeklyCycle"
  Storage = File
  Messages = Standard
  Pool = Default
  Priority = 10
  Write Bootstrap = "/var/lib/bacula/%c.bsr"
}

FileSet {
  Name = "MyApp Files"
  Include {
    Options {
      signature = MD5
      compression = GZIP
    }
    File = /opt/myapp
    File = /var/lib/postgresql/15/main
  }
  Exclude {
    File = /opt/myapp/tmp
    File = /opt/myapp/cache
  }
}

Schedule {
  Name = "WeeklyCycle"
  Run = Full 1st sun at 23:05
  Run = Differential 2nd-5th sun at 23:05
  Run = Incremental mon-sat at 23:05
}
```

### Duplicity - Backup chiffr√©

**Installation** :

```bash
sudo apt install duplicity python3-boto3
```

**Script de backup vers AWS S3** :

```bash
#!/bin/bash
# duplicity-backup.sh

export AWS_ACCESS_KEY_ID="your_access_key"
export AWS_SECRET_ACCESS_KEY="your_secret_key"
export PASSPHRASE="encryption_passphrase"

SOURCE="/opt/myapp"
DEST="s3://my-backups/myapp/"

# Backup incr√©mental
duplicity \
    --full-if-older-than 7D \
    --exclude /opt/myapp/tmp \
    --exclude /opt/myapp/logs \
    $SOURCE $DEST

# Nettoyer les anciens backups
duplicity remove-older-than 30D --force $DEST

# V√©rifier
duplicity collection-status $DEST

unset PASSPHRASE
```

**Restauration** :

```bash
#!/bin/bash
# duplicity-restore.sh

export AWS_ACCESS_KEY_ID="your_access_key"
export AWS_SECRET_ACCESS_KEY="your_secret_key"
export PASSPHRASE="encryption_passphrase"

SOURCE="s3://my-backups/myapp/"
DEST="/restore/myapp"

# Restaurer la version la plus r√©cente
duplicity restore $SOURCE $DEST

# Ou restaurer √† une date sp√©cifique
# duplicity restore --time 2025-10-01 $SOURCE $DEST

unset PASSPHRASE
```

### Rsync pour la synchronisation

**Script de synchronisation continue** :

```bash
#!/bin/bash
# rsync-mirror.sh - Miroir en temps quasi-r√©el

SOURCE="/opt/myapp/"
DEST="backup-server:/backups/myapp/"
LOG="/var/log/rsync-mirror.log"

# Synchronisation continue
while true; do
    rsync -avz \
        --delete \
        --exclude 'tmp/' \
        --exclude 'cache/' \
        --exclude '*.log' \
        --log-file="$LOG" \
        "$SOURCE" "$DEST"

    if [ $? -eq 0 ]; then
        echo "[$(date)] Synchronisation r√©ussie" >> "$LOG"
    else
        echo "[$(date)] √âchec de synchronisation" >> "$LOG"
    fi

    # Attendre 5 minutes
    sleep 300
done
```

## Strat√©gies cloud

### Backup sur AWS S3

```bash
#!/bin/bash
# backup-to-s3.sh

BACKUP_FILE="/backups/myapp/myapp_$(date +%Y%m%d).tar.gz"
S3_BUCKET="s3://my-disaster-recovery-bucket"
S3_REGION="eu-west-1"

# Cr√©er le backup
tar -czf "$BACKUP_FILE" /opt/myapp

# Upload vers S3 avec storage class Glacier pour √©conomiser
aws s3 cp "$BACKUP_FILE" "$S3_BUCKET/" \
    --storage-class GLACIER \
    --region "$S3_REGION"

if [ $? -eq 0 ]; then
    echo "‚úì Backup upload√© vers S3"

    # Supprimer le fichier local pour √©conomiser l'espace
    rm "$BACKUP_FILE"
else
    echo "‚úó √âchec de l'upload S3"
    exit 1
fi

# Configurer le lifecycle pour suppression automatique apr√®s 90 jours
aws s3api put-bucket-lifecycle-configuration \
    --bucket my-disaster-recovery-bucket \
    --lifecycle-configuration file://lifecycle.json
```

**lifecycle.json** :

```json
{
  "Rules": [
    {
      "Id": "DeleteOldBackups",
      "Status": "Enabled",
      "Prefix": "",
      "Expiration": {
        "Days": 90
      }
    }
  ]
}
```

### Backup cross-region

```bash
#!/bin/bash
# backup-cross-region.sh

PRIMARY_REGION="eu-west-1"
SECONDARY_REGION="us-east-1"
BUCKET_NAME="my-backups"

# Upload vers la r√©gion primaire
aws s3 cp backup.tar.gz s3://$BUCKET_NAME/ --region $PRIMARY_REGION

# Copier vers la r√©gion secondaire
aws s3 cp s3://$BUCKET_NAME/backup.tar.gz \
    s3://$BUCKET_NAME-$SECONDARY_REGION/ \
    --source-region $PRIMARY_REGION \
    --region $SECONDARY_REGION

echo "‚úì Backup r√©pliqu√© dans 2 r√©gions"
```

## Checklist finale de disaster recovery

### Pr√©paration

- [ ] **RTO/RPO d√©finis** et document√©s
- [ ] **Plan de reprise document√©** et accessible hors ligne
- [ ] **Contacts d'urgence** √† jour
- [ ] **Sauvegardes automatis√©es** configur√©es
- [ ] **Sauvegardes offsite** actives
- [ ] **Tests de restauration** programm√©s (au moins trimestriels)
- [ ] **Monitoring des backups** en place
- [ ] **Alertes configur√©es** (email, SMS, Slack)

### Infrastructure

- [ ] **Serveur de secours** disponible
- [ ] **Configuration en haute disponibilit√©** (si applicable)
- [ ] **R√©plication base de donn√©es** configur√©e
- [ ] **Load balancer** avec healthchecks
- [ ] **DNS avec TTL court** pour basculement rapide
- [ ] **Acc√®s r√©seau s√©curis√©** au site de secours

### Documentation

- [ ] **Proc√©dures de restauration** test√©es et √† jour
- [ ] **Diagrammes d'architecture** √† jour
- [ ] **Inventaire des syst√®mes** complet
- [ ] **Credentials** sauvegard√©s de mani√®re s√©curis√©e
- [ ] **Runbook** accessible 24/7
- [ ] **Contacts fournisseurs** (h√©bergeur, cloud, etc.)

### Formation

- [ ] **√âquipe form√©e** aux proc√©dures
- [ ] **Simulations de sinistres** r√©guli√®res (annuelles minimum)
- [ ] **R√¥les et responsabilit√©s** clairs
- [ ] **Communication de crise** pr√©par√©e

### Compliance

- [ ] **Conformit√© RGPD** pour les backups
- [ ] **Chiffrement des backups** sensibles
- [ ] **Logs d'acc√®s** aux backups
- [ ] **Audit trail** des restaurations
- [ ] **Politique de r√©tention** respect√©e

## Conclusion

Le disaster recovery n'est pas une option, c'est une n√©cessit√© pour toute application professionnelle. Les points cl√©s √† retenir :

üéØ **Pr√©vention** : Le meilleur sinistre est celui qui n'arrive pas
- Monitoring proactif
- Haute disponibilit√©
- Tests r√©guliers

üíæ **Pr√©paration** : Avoir un plan solide
- Backups automatis√©s et test√©s
- Documentation claire
- √âquipe form√©e

‚ö° **R√©action** : Agir vite et bien
- Proc√©dures document√©es
- Communication efficace
- Post-mortem syst√©matique

üîÑ **Am√©lioration continue** : Apprendre de chaque incident
- Mettre √† jour les proc√©dures
- Am√©liorer les outils
- Former l'√©quipe

**N'oubliez jamais** : Un backup non test√© n'est pas un backup !

---

**Ressources compl√©mentaires** :
- NIST Guidelines for Disaster Recovery : https://www.nist.gov/
- ISO 22301 Business Continuity Management
- DORA (Digital Operational Resilience Act) pour l'UE
- Bacula Documentation : https://www.bacula.org/documentation/
- AWS Disaster Recovery : https://aws.amazon.com/disaster-recovery/

‚è≠Ô∏è [D√©veloppement de Jeux](/23-developpement-jeux/README.md)
