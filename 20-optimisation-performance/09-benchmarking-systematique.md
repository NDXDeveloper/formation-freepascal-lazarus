üîù Retour au [Sommaire](/SOMMAIRE.md)

# 20.9 Benchmarking Syst√©matique

## Introduction

Le **benchmarking** est l'art de **mesurer pr√©cis√©ment les performances** de votre code pour identifier les goulots d'√©tranglement et valider vos optimisations. C'est une comp√©tence essentielle pour tout d√©veloppeur souhaitant cr√©er des applications performantes.

### Pourquoi faire du benchmarking ?

**Analogie simple :** Imaginez que vous voulez am√©liorer votre temps sur un parcours de course. Sans chronom√®tre, comment sauriez-vous si vous progressez ? Le benchmarking, c'est votre chronom√®tre pour le code.

**R√®gle d'or :** "On ne peut optimiser que ce qu'on mesure" - Ne jamais optimiser √† l'aveugle !

### Les trois piliers du benchmarking

1. **Mesure** : Collecter des donn√©es pr√©cises sur les performances
2. **Comparaison** : √âvaluer diff√©rentes approches
3. **Validation** : S'assurer que les optimisations fonctionnent r√©ellement

---

## 1. Mesure du Temps d'Ex√©cution

### 1.1 M√©thode Simple avec Now()

La m√©thode la plus basique pour mesurer le temps :

```pascal
uses
  SysUtils, DateUtils;

procedure BenchmarkSimple;
var
  StartTime, EndTime: TDateTime;
  i, Sum: Integer;
begin
  StartTime := Now;

  // Code √† mesurer
  Sum := 0;
  for i := 1 to 10000000 do
    Sum := Sum + i;

  EndTime := Now;

  WriteLn('Temps d''ex√©cution : ', MilliSecondsBetween(EndTime, StartTime), ' ms');
  WriteLn('R√©sultat : ', Sum);
end;
```

**Avantages :**
- Tr√®s simple √† utiliser
- Fonctionne sur Windows et Ubuntu

**Inconv√©nients :**
- Pr√©cision limit√©e (millisecondes)
- Pas adapt√© pour les op√©rations tr√®s rapides

### 1.2 Utilisation de GetTickCount64 (Plus Pr√©cis)

Pour une meilleure pr√©cision, utilisez `GetTickCount64` :

```pascal
{$IFDEF WINDOWS}
uses
  Windows;
{$ELSE}
uses
  Unix, BaseUnix;

function GetTickCount64: QWord;
var
  ts: TTimeSpec;
begin
  clock_gettime(CLOCK_MONOTONIC, @ts);
  Result := (QWord(ts.tv_sec) * 1000) + (ts.tv_nsec div 1000000);
end;
{$ENDIF}

procedure BenchmarkPrecis;
var
  StartTicks, EndTicks: QWord;
  i: Integer;
begin
  StartTicks := GetTickCount64;

  // Code √† mesurer
  for i := 1 to 1000000 do
    Sqrt(i);

  EndTicks := GetTickCount64;

  WriteLn('Temps : ', EndTicks - StartTicks, ' ms');
end;
```

### 1.3 Haute Pr√©cision avec QueryPerformanceCounter (Windows)

Pour des mesures extr√™mement pr√©cises sur Windows :

```pascal
{$IFDEF WINDOWS}
uses
  Windows;

function GetPreciseTime: Double;
var
  Frequency, Counter: Int64;
begin
  QueryPerformanceFrequency(Frequency);
  QueryPerformanceCounter(Counter);
  Result := Counter / Frequency; // Temps en secondes
end;
{$ENDIF}

procedure BenchmarkHautePrecision;
var
  StartTime, EndTime: Double;
begin
  {$IFDEF WINDOWS}
  StartTime := GetPreciseTime;

  // Code √† mesurer
  Sleep(100);

  EndTime := GetPreciseTime;

  WriteLn('Temps : ', FormatFloat('0.000000', (EndTime - StartTime) * 1000), ' ms');
  {$ENDIF}
end;
```

### 1.4 Classe Universelle de Chronom√©trage

Cr√©ons une classe r√©utilisable qui fonctionne sur toutes les plateformes :

```pascal
type
  TStopwatch = class
  private
    FStartTime: QWord;
    FElapsedTime: QWord;
    FIsRunning: Boolean;
    function GetCurrentTicks: QWord;
  public
    constructor Create;
    procedure Start;
    procedure Stop;
    procedure Reset;
    function ElapsedMilliseconds: QWord;
    function ElapsedSeconds: Double;
    property IsRunning: Boolean read FIsRunning;
  end;

constructor TStopwatch.Create;
begin
  FIsRunning := False;
  FElapsedTime := 0;
end;

function TStopwatch.GetCurrentTicks: QWord;
begin
  {$IFDEF WINDOWS}
  Result := GetTickCount64;
  {$ELSE}
  var ts: TTimeSpec;
  clock_gettime(CLOCK_MONOTONIC, @ts);
  Result := (QWord(ts.tv_sec) * 1000) + (ts.tv_nsec div 1000000);
  {$ENDIF}
end;

procedure TStopwatch.Start;
begin
  if not FIsRunning then
  begin
    FStartTime := GetCurrentTicks;
    FIsRunning := True;
  end;
end;

procedure TStopwatch.Stop;
begin
  if FIsRunning then
  begin
    FElapsedTime := FElapsedTime + (GetCurrentTicks - FStartTime);
    FIsRunning := False;
  end;
end;

procedure TStopwatch.Reset;
begin
  FElapsedTime := 0;
  FIsRunning := False;
end;

function TStopwatch.ElapsedMilliseconds: QWord;
begin
  Result := FElapsedTime;
  if FIsRunning then
    Result := Result + (GetCurrentTicks - FStartTime);
end;

function TStopwatch.ElapsedSeconds: Double;
begin
  Result := ElapsedMilliseconds / 1000.0;
end;
```

**Utilisation :**

```pascal
var
  SW: TStopwatch;
  i: Integer;
begin
  SW := TStopwatch.Create;
  try
    SW.Start;

    // Code √† mesurer
    for i := 1 to 1000000 do
      Sqrt(i);

    SW.Stop;

    WriteLn('Temps √©coul√© : ', SW.ElapsedMilliseconds, ' ms');
    WriteLn('Soit : ', FormatFloat('0.00', SW.ElapsedSeconds), ' secondes');
  finally
    SW.Free;
  end;
end;
```

---

## 2. Framework de Benchmarking Complet

### 2.1 Classe de Benchmark R√©utilisable

Cr√©ons un syst√®me professionnel pour comparer plusieurs impl√©mentations :

```pascal
type
  TBenchmarkProc = procedure;

  TBenchmarkResult = record
    Name: string;
    ExecutionTime: QWord;  // en millisecondes
    Iterations: Integer;
    TimePerIteration: Double;  // en microsecondes
  end;

  TBenchmarkSuite = class
  private
    FResults: array of TBenchmarkResult;
    FIterations: Integer;
    FWarmupRuns: Integer;
  public
    constructor Create(AIterations: Integer = 1000; AWarmupRuns: Integer = 10);
    procedure AddBenchmark(const AName: string; AProc: TBenchmarkProc);
    procedure Run;
    procedure PrintResults;
    procedure PrintComparison;
  end;

constructor TBenchmarkSuite.Create(AIterations, AWarmupRuns: Integer);
begin
  FIterations := AIterations;
  FWarmupRuns := AWarmupRuns;
  SetLength(FResults, 0);
end;

procedure TBenchmarkSuite.AddBenchmark(const AName: string; AProc: TBenchmarkProc);
var
  SW: TStopwatch;
  i: Integer;
  Idx: Integer;
begin
  Idx := Length(FResults);
  SetLength(FResults, Idx + 1);

  FResults[Idx].Name := AName;
  FResults[Idx].Iterations := FIterations;

  // Warm-up (important pour √©viter les faux r√©sultats)
  WriteLn('Warm-up pour "', AName, '"...');
  for i := 1 to FWarmupRuns do
    AProc();

  // Mesure r√©elle
  WriteLn('Benchmark de "', AName, '"...');
  SW := TStopwatch.Create;
  try
    SW.Start;
    for i := 1 to FIterations do
      AProc();
    SW.Stop;

    FResults[Idx].ExecutionTime := SW.ElapsedMilliseconds;
    FResults[Idx].TimePerIteration :=
      (SW.ElapsedMilliseconds * 1000.0) / FIterations; // en microsecondes
  finally
    SW.Free;
  end;
end;

procedure TBenchmarkSuite.Run;
begin
  WriteLn('=== D√©marrage de la suite de benchmarks ===');
  WriteLn('It√©rations par test : ', FIterations);
  WriteLn('Runs de warm-up : ', FWarmupRuns);
  WriteLn;
end;

procedure TBenchmarkSuite.PrintResults;
var
  i: Integer;
begin
  WriteLn;
  WriteLn('=== R√âSULTATS ===');
  WriteLn;

  for i := 0 to High(FResults) do
  begin
    WriteLn('Test : ', FResults[i].Name);
    WriteLn('  Temps total   : ', FResults[i].ExecutionTime, ' ms');
    WriteLn('  Par it√©ration : ', FormatFloat('0.000', FResults[i].TimePerIteration), ' Œºs');
    WriteLn;
  end;
end;

procedure TBenchmarkSuite.PrintComparison;
var
  i: Integer;
  BestTime: QWord;
  Ratio: Double;
begin
  if Length(FResults) = 0 then Exit;

  // Trouver le meilleur temps
  BestTime := FResults[0].ExecutionTime;
  for i := 1 to High(FResults) do
    if FResults[i].ExecutionTime < BestTime then
      BestTime := FResults[i].ExecutionTime;

  WriteLn('=== COMPARAISON ===');
  WriteLn;

  for i := 0 to High(FResults) do
  begin
    Ratio := FResults[i].ExecutionTime / BestTime;
    WriteLn(FResults[i].Name);
    if FResults[i].ExecutionTime = BestTime then
      WriteLn('  ‚úì PLUS RAPIDE (r√©f√©rence)')
    else
      WriteLn('  ', FormatFloat('0.00', Ratio), 'x plus lent');
    WriteLn;
  end;
end;
```

### 2.2 Exemple d'Utilisation Pratique

Comparons diff√©rentes m√©thodes pour calculer la somme d'un tableau :

```pascal
const
  ARRAY_SIZE = 10000;

var
  TestArray: array[0..ARRAY_SIZE-1] of Integer;

procedure InitTestArray;
var
  i: Integer;
begin
  for i := 0 to ARRAY_SIZE-1 do
    TestArray[i] := i + 1;
end;

procedure SumWithForLoop;
var
  i, Sum: Integer;
begin
  Sum := 0;
  for i := 0 to ARRAY_SIZE-1 do
    Sum := Sum + TestArray[i];
end;

procedure SumWithWhileLoop;
var
  i, Sum: Integer;
begin
  Sum := 0;
  i := 0;
  while i < ARRAY_SIZE do
  begin
    Sum := Sum + TestArray[i];
    Inc(i);
  end;
end;

procedure SumWithPointer;
var
  P: PInteger;
  PEnd: PInteger;
  Sum: Integer;
begin
  Sum := 0;
  P := @TestArray[0];
  PEnd := @TestArray[ARRAY_SIZE];
  while P < PEnd do
  begin
    Sum := Sum + P^;
    Inc(P);
  end;
end;

procedure RunSumBenchmark;
var
  Suite: TBenchmarkSuite;
begin
  InitTestArray;

  Suite := TBenchmarkSuite.Create(10000, 100);
  try
    Suite.Run;

    Suite.AddBenchmark('For Loop', @SumWithForLoop);
    Suite.AddBenchmark('While Loop', @SumWithWhileLoop);
    Suite.AddBenchmark('Pointer Arithmetic', @SumWithPointer);

    Suite.PrintResults;
    Suite.PrintComparison;
  finally
    Suite.Free;
  end;
end;
```

---

## 3. Benchmarking de Structures de Donn√©es

Comparons les performances de diff√©rentes structures :

```pascal
type
  TDataStructureBenchmark = class
  private
    FItemCount: Integer;
  public
    constructor Create(AItemCount: Integer = 10000);
    procedure BenchmarkTList;
    procedure BenchmarkTStringList;
    procedure BenchmarkTDictionary;
    procedure BenchmarkArray;
    procedure RunAll;
  end;

constructor TDataStructureBenchmark.Create(AItemCount: Integer);
begin
  FItemCount := AItemCount;
end;

procedure TDataStructureBenchmark.BenchmarkTList;
var
  List: TList;
  i: Integer;
  SW: TStopwatch;
begin
  SW := TStopwatch.Create;
  List := TList.Create;
  try
    // Insertion
    SW.Start;
    for i := 0 to FItemCount-1 do
      List.Add(Pointer(i));
    SW.Stop;
    WriteLn('TList - Insertion : ', SW.ElapsedMilliseconds, ' ms');

    // Recherche
    SW.Reset;
    SW.Start;
    for i := 0 to FItemCount-1 do
      List.IndexOf(Pointer(i div 2));
    SW.Stop;
    WriteLn('TList - Recherche : ', SW.ElapsedMilliseconds, ' ms');

  finally
    List.Free;
    SW.Free;
  end;
end;

procedure TDataStructureBenchmark.BenchmarkTDictionary;
var
  Dict: TDictionary<Integer, Integer>;
  i, Val: Integer;
  SW: TStopwatch;
begin
  SW := TStopwatch.Create;
  Dict := TDictionary<Integer, Integer>.Create;
  try
    // Insertion
    SW.Start;
    for i := 0 to FItemCount-1 do
      Dict.Add(i, i * 2);
    SW.Stop;
    WriteLn('TDictionary - Insertion : ', SW.ElapsedMilliseconds, ' ms');

    // Recherche
    SW.Reset;
    SW.Start;
    for i := 0 to FItemCount-1 do
      Dict.TryGetValue(i div 2, Val);
    SW.Stop;
    WriteLn('TDictionary - Recherche : ', SW.ElapsedMilliseconds, ' ms');

  finally
    Dict.Free;
    SW.Free;
  end;
end;

procedure TDataStructureBenchmark.RunAll;
begin
  WriteLn('=== Benchmark des structures de donn√©es ===');
  WriteLn('Nombre d''√©l√©ments : ', FItemCount);
  WriteLn;

  BenchmarkArray;
  WriteLn;
  BenchmarkTList;
  WriteLn;
  BenchmarkTStringList;
  WriteLn;
  BenchmarkTDictionary;
end;
```

---

## 4. Profiling M√©moire

### 4.1 Mesure de la Consommation M√©moire

Sur Windows et Ubuntu, on peut surveiller la m√©moire utilis√©e :

```pascal
uses
  {$IFDEF WINDOWS}
  Windows,
  {$ELSE}
  Unix, BaseUnix,
  {$ENDIF}
  SysUtils;

function GetMemoryUsage: Int64;
{$IFDEF WINDOWS}
var
  MemCounters: TProcessMemoryCounters;
{$ENDIF}
begin
  {$IFDEF WINDOWS}
  MemCounters.cb := SizeOf(MemCounters);
  if GetProcessMemoryInfo(GetCurrentProcess, @MemCounters, SizeOf(MemCounters)) then
    Result := MemCounters.WorkingSetSize
  else
    Result := 0;
  {$ELSE}
  // Sur Linux, lecture depuis /proc/self/status
  // Impl√©mentation simplifi√©e
  Result := 0; // √Ä impl√©menter selon vos besoins
  {$ENDIF}
end;

procedure BenchmarkMemory;
var
  MemBefore, MemAfter: Int64;
  List: TList;
  i: Integer;
begin
  MemBefore := GetMemoryUsage;

  // Allocation m√©moire
  List := TList.Create;
  try
    for i := 0 to 1000000 do
      List.Add(Pointer(i));

    MemAfter := GetMemoryUsage;

    WriteLn('M√©moire avant : ', MemBefore div 1024, ' KB');
    WriteLn('M√©moire apr√®s : ', MemAfter div 1024, ' KB');
    WriteLn('Diff√©rence : ', (MemAfter - MemBefore) div 1024, ' KB');
  finally
    List.Free;
  end;
end;
```

### 4.2 D√©tection de Fuites M√©moire avec HeapTrc

FreePascal inclut un excellent outil de d√©tection de fuites :

```pascal
{$IFDEF DEBUG}
  {$APPTYPE CONSOLE}
  {$DEFINE HEAPTRC}
{$ENDIF}

program MemoryLeakTest;

uses
  {$IFDEF HEAPTRC}
  HeapTrc,
  {$ENDIF}
  Classes, SysUtils;

var
  List: TStringList;
begin
  // Configurer HeapTrc
  {$IFDEF HEAPTRC}
  SetHeapTraceOutput('heap.trc');
  {$ENDIF}

  // Code avec fuite volontaire
  List := TStringList.Create;
  List.Add('Test');
  // Oubli volontaire du Free !

  WriteLn('Fin du programme');
  // HeapTrc affichera un rapport de fuite
end.
```

Le fichier `heap.trc` contiendra un rapport d√©taill√© des fuites.

---

## 5. Benchmarking Multi-plateforme

### 5.1 Consid√©rations Windows vs Ubuntu

Les performances peuvent varier entre les plateformes :

```pascal
procedure BenchmarkPlatformDifferences;
var
  SW: TStopwatch;
  i: Integer;
  F: TextFile;
begin
  WriteLn('Plateforme : ');
  {$IFDEF WINDOWS}
  WriteLn('  Windows');
  {$ENDIF}
  {$IFDEF UNIX}
  WriteLn('  Unix/Linux');
  {$ENDIF}
  WriteLn('Architecture : ', SizeOf(Pointer) * 8, ' bits');
  WriteLn;

  SW := TStopwatch.Create;
  try
    // Test I/O fichier
    SW.Start;
    AssignFile(F, 'test.txt');
    Rewrite(F);
    for i := 1 to 10000 do
      WriteLn(F, 'Ligne ', i);
    CloseFile(F);
    SW.Stop;

    WriteLn('√âcriture fichier : ', SW.ElapsedMilliseconds, ' ms');

    // Nettoyage
    DeleteFile('test.txt');
  finally
    SW.Free;
  end;
end;
```

### 5.2 Script de Benchmark Automatis√©

Cr√©ez un script pour lancer les benchmarks sur les deux OS :

**Windows (benchmark.bat) :**
```batch
@echo off
echo === Benchmarks Windows ===
fpc -O3 benchmark.pas
benchmark.exe > results_windows.txt
echo R√©sultats sauvegard√©s dans results_windows.txt
```

**Ubuntu (benchmark.sh) :**
```bash
#!/bin/bash
echo "=== Benchmarks Ubuntu ==="
fpc -O3 benchmark.pas
./benchmark > results_ubuntu.txt
echo "R√©sultats sauvegard√©s dans results_ubuntu.txt"
```

---

## 6. Analyse et Visualisation des R√©sultats

### 6.1 Export des R√©sultats en CSV

```pascal
type
  TBenchmarkExporter = class
  public
    class procedure ExportToCSV(const Results: array of TBenchmarkResult;
                                const FileName: string);
  end;

class procedure TBenchmarkExporter.ExportToCSV(
  const Results: array of TBenchmarkResult; const FileName: string);
var
  F: TextFile;
  i: Integer;
begin
  AssignFile(F, FileName);
  Rewrite(F);
  try
    // En-t√™te
    WriteLn(F, 'Test,Temps Total (ms),Iterations,Temps/Iteration (Œºs)');

    // Donn√©es
    for i := 0 to High(Results) do
      WriteLn(F,
        Results[i].Name, ',',
        Results[i].ExecutionTime, ',',
        Results[i].Iterations, ',',
        FormatFloat('0.000', Results[i].TimePerIteration)
      );

    WriteLn('R√©sultats export√©s vers : ', FileName);
  finally
    CloseFile(F);
  end;
end;
```

### 6.2 G√©n√©ration de Graphiques avec TAChart

```pascal
uses
  TAGraph, TASeries, TAChartUtils;

procedure GenerateBenchmarkChart(const Results: array of TBenchmarkResult);
var
  Chart: TChart;
  Series: TBarSeries;
  i: Integer;
begin
  Chart := TChart.Create(nil);
  Series := TBarSeries.Create(Chart);
  try
    Series.Title := 'Temps d''ex√©cution';

    for i := 0 to High(Results) do
      Series.AddXY(i, Results[i].ExecutionTime, Results[i].Name);

    Chart.AddSeries(Series);
    Chart.Title.Text.Text := 'Comparaison des performances';

    // Sauvegarder le graphique
    Chart.SaveToFile(TPortableNetworkGraphic, 'benchmark_chart.png');
    WriteLn('Graphique sauvegard√© : benchmark_chart.png');
  finally
    Chart.Free;
  end;
end;
```

---

## 7. Bonnes Pratiques de Benchmarking

### ‚úÖ √Ä Faire

1. **Toujours faire un warm-up** : Les premi√®res ex√©cutions sont souvent plus lentes (cache CPU, JIT, etc.)

2. **Ex√©cuter plusieurs it√©rations** : Une seule mesure n'est pas fiable

3. **Mesurer dans des conditions r√©elles** : Mode Release, optimisations activ√©es

```pascal
// Compiler avec optimisations
// fpc -O3 -CX -XX benchmark.pas
```

4. **Isoler le code √† mesurer** : Ne mesurez que ce qui vous int√©resse

5. **D√©sactiver les autres processus** : Fermer les applications gourmandes pendant les tests

6. **Comparer des choses comparables** : M√™me quantit√© de travail, m√™me complexit√©

7. **Documenter l'environnement** :
```pascal
procedure PrintEnvironment;
begin
  WriteLn('=== Environnement ===');
  WriteLn('OS : ', {$I %FPCTARGETOS%});
  WriteLn('CPU : ', {$I %FPCTARGETCPU%});
  WriteLn('Compilateur : FPC ', {$I %FPCVERSION%});
  WriteLn('Date : ', DateTimeToStr(Now));
  WriteLn;
end;
```

### ‚ùå √Ä √âviter

1. **Optimiser pr√©matur√©ment** : Mesurez d'abord, optimisez ensuite
2. **Ignorer le warm-up** : Fausses conclusions
3. **Mesurer en mode Debug** : Les r√©sultats ne sont pas repr√©sentatifs
4. **Utiliser WriteLn dans le code mesur√©** : Les I/O sont tr√®s lentes
5. **Oublier de compiler avec -O3** : Sans optimisations, tout est lent

---

## 8. Exemple Complet : Comparaison d'Algorithmes de Tri

```pascal
program SortBenchmark;

uses
  SysUtils, Classes;

const
  ARRAY_SIZE = 10000;

type
  TIntArray = array of Integer;

var
  TestArray: TIntArray;

procedure GenerateRandomArray(var Arr: TIntArray; Size: Integer);
var
  i: Integer;
begin
  SetLength(Arr, Size);
  Randomize;
  for i := 0 to Size-1 do
    Arr[i] := Random(100000);
end;

procedure BubbleSort(var Arr: TIntArray);
var
  i, j, Temp: Integer;
begin
  for i := 0 to High(Arr) do
    for j := 0 to High(Arr) - i - 1 do
      if Arr[j] > Arr[j+1] then
      begin
        Temp := Arr[j];
        Arr[j] := Arr[j+1];
        Arr[j+1] := Temp;
      end;
end;

procedure QuickSort(var Arr: TIntArray; Left, Right: Integer);
var
  i, j, Pivot, Temp: Integer;
begin
  if Left < Right then
  begin
    Pivot := Arr[(Left + Right) div 2];
    i := Left;
    j := Right;
    while i <= j do
    begin
      while Arr[i] < Pivot do Inc(i);
      while Arr[j] > Pivot do Dec(j);
      if i <= j then
      begin
        Temp := Arr[i];
        Arr[i] := Arr[j];
        Arr[j] := Temp;
        Inc(i);
        Dec(j);
      end;
    end;
    QuickSort(Arr, Left, j);
    QuickSort(Arr, i, Right);
  end;
end;

procedure RunSortBenchmarks;
var
  Suite: TBenchmarkSuite;
  TempArray: TIntArray;
begin
  GenerateRandomArray(TestArray, ARRAY_SIZE);

  Suite := TBenchmarkSuite.Create(10, 2);
  try
    Suite.Run;

    // Bubble Sort
    Suite.AddBenchmark('Bubble Sort',
      procedure
      begin
        TempArray := Copy(TestArray);
        BubbleSort(TempArray);
      end
    );

    // Quick Sort
    Suite.AddBenchmark('Quick Sort',
      procedure
      begin
        TempArray := Copy(TestArray);
        QuickSort(TempArray, 0, High(TempArray));
      end
    );

    Suite.PrintResults;
    Suite.PrintComparison;
  finally
    Suite.Free;
  end;
end;

begin
  PrintEnvironment;
  RunSortBenchmarks;
  ReadLn;
end.
```

---

## 9. Outils Externes de Profiling

### 9.1 Sur Windows

**Intel VTune Profiler** (gratuit pour un usage personnel)
- Profiling CPU d√©taill√©
- Analyse des hotspots
- Visualisation graphique

**Visual Studio Profiler**
- Inclus avec Visual Studio Community
- Peut profiler les ex√©cutables FreePascal

### 9.2 Sur Ubuntu/Linux

**Valgrind Callgrind**
```bash
# Compiler avec symboles de debug
fpc -g benchmark.pas

# Profiler avec Callgrind
valgrind --tool=callgrind ./benchmark

# Visualiser avec KCacheGrind
kcachegrind callgrind.out.*
```

**perf** (outil Linux natif)
```bash
# Enregistrer un profil
perf record -g ./benchmark

# Analyser les r√©sultats
perf report
```

**gprof** (GNU Profiler)
```bash
# Compiler avec support gprof
fpc -pg benchmark.pas

# Ex√©cuter
./benchmark

# Analyser
gprof benchmark gmon.out > analysis.txt
```

---

## 10. Int√©gration Continue des Benchmarks

### 10.1 Script de Benchmark Automatique

```bash
#!/bin/bash
# benchmark_ci.sh

echo "=== Benchmark CI ==="
echo "Date: $(date)"
echo "Commit: $(git rev-parse --short HEAD)"
echo ""

# Compiler
fpc -O3 benchmark.pas

# Ex√©cuter
./benchmark > benchmark_results.txt

# Comparer avec la baseline
if [ -f "baseline_results.txt" ]; then
    echo "Comparaison avec la baseline..."
    # Script de comparaison personnalis√©
    python3 compare_benchmarks.py baseline_results.txt benchmark_results.txt
fi

# Archiver les r√©sultats
mkdir -p benchmark_history
cp benchmark_results.txt "benchmark_history/bench_$(date +%Y%m%d_%H%M%S).txt"
```

### 10.2 GitHub Actions pour Benchmarks Multi-OS

```yaml
name: Benchmarks

on: [push, pull_request]

jobs:
  benchmark:
    strategy:
      matrix:
        os: [ubuntu-latest, windows-latest]

    runs-on: ${{ matrix.os }}

    steps:
      - uses: actions/checkout@v2

      - name: Install FreePascal
        run: |
          # Installation selon l'OS

      - name: Run Benchmarks
        run: |
          fpc -O3 benchmark.pas
          ./benchmark

      - name: Upload Results
        uses: actions/upload-artifact@v2
        with:
          name: benchmark-results-${{ matrix.os }}
          path: benchmark_results.txt
```

---

## Conclusion

Le benchmarking syst√©matique est **essentiel** pour d√©velopper des applications performantes :

üéØ **Principes cl√©s :**
- Toujours mesurer avant d'optimiser
- Comparer plusieurs approches
- Documenter l'environnement de test
- Automatiser les benchmarks

üìä **Outils essentiels :**
- TStopwatch pour mesures simples
- TBenchmarkSuite pour comparaisons
- HeapTrc pour la m√©moire
- Valgrind/perf sur Linux
- Profilers pour analyse approfondie

üîÑ **Workflow recommand√© :**
1. **Identifier** le code lent avec un profiler
2. **Mesurer** les performances actuelles
3. **Optimiser** une seule chose √† la fois
4. **Re-mesurer** pour valider l'am√©lioration
5. **Documenter** les r√©sultats

üí° **Rappelez-vous :**
> "Premature optimization is the root of all evil" - Donald Knuth

Ne perdez pas de temps √† optimiser du code qui n'est pas un goulot d'√©tranglement. Mesurez d'abord, optimisez ensuite !

---

## Annexe A : Template de Rapport de Benchmark

```pascal
procedure GenerateBenchmarkReport(const Results: array of TBenchmarkResult);
var
  F: TextFile;
  i: Integer;
begin
  AssignFile(F, 'benchmark_report.txt');
  Rewrite(F);
  try
    WriteLn(F, '‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó');
    WriteLn(F, '‚ïë          RAPPORT DE BENCHMARK                          ‚ïë');
    WriteLn(F, '‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù');
    WriteLn(F);

    WriteLn(F, 'Date        : ', DateTimeToStr(Now));
    WriteLn(F, 'Compilateur : FPC ', {$I %FPCVERSION%});
    WriteLn(F, 'Plateforme  : ', {$I %FPCTARGETOS%}, ' - ', {$I %FPCTARGETCPU%});
    WriteLn(F, 'Optimisation: -O3 -CX -XX');
    WriteLn(F);
    WriteLn(F, '‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ');
    WriteLn(F);

    for i := 0 to High(Results) do
    begin
      WriteLn(F, 'Test #', i+1, ' : ', Results[i].Name);
      WriteLn(F, '  ‚Ä¢ It√©rations    : ', Results[i].Iterations);
      WriteLn(F, '  ‚Ä¢ Temps total   : ', Results[i].ExecutionTime, ' ms');
      WriteLn(F, '  ‚Ä¢ Temps/iter    : ',
              FormatFloat('0.000', Results[i].TimePerIteration), ' Œºs');
      WriteLn(F);
    end;

    WriteLn(F, '‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ');
    WriteLn(F, 'Rapport g√©n√©r√© automatiquement');

  finally
    CloseFile(F);
  end;

  WriteLn('Rapport sauvegard√© : benchmark_report.txt');
end;
```

---

## Annexe B : Checklist du Benchmarking

### Avant de commencer

- [ ] J'ai identifi√© le code √† optimiser (profiling pr√©alable)
- [ ] J'ai d√©fini des m√©triques claires (temps, m√©moire, throughput)
- [ ] J'ai ferm√© les applications inutiles
- [ ] J'ai d√©sactiv√© les √©conomies d'√©nergie

### Configuration du benchmark

- [ ] Mode Release activ√©
- [ ] Optimisations du compilateur (-O3)
- [ ] Warm-up configur√© (au moins 10 it√©rations)
- [ ] Nombre d'it√©rations suffisant (>1000 pour petites op√©rations)
- [ ] Environnement document√© (OS, CPU, RAM, compilateur)

### Pendant l'ex√©cution

- [ ] R√©sultats coh√©rents entre les runs
- [ ] Pas de variations anormales
- [ ] Statistiques collect√©es (min, max, moyenne, √©cart-type)

### Apr√®s les benchmarks

- [ ] R√©sultats export√©s (CSV, JSON)
- [ ] Graphiques g√©n√©r√©s
- [ ] Comparaison avec baseline
- [ ] Rapport r√©dig√©
- [ ] Code commit√© avec les r√©sultats

---

## Annexe C : Statistiques Avanc√©es

Pour des benchmarks plus pr√©cis, calculez des statistiques :

```pascal
type
  TBenchmarkStats = record
    Min: QWord;
    Max: QWord;
    Mean: Double;
    Median: QWord;
    StdDev: Double;
  end;

function CalculateStats(const Timings: array of QWord): TBenchmarkStats;
var
  i: Integer;
  Sum, SumSquares: Double;
  SortedTimings: array of QWord;
begin
  if Length(Timings) = 0 then Exit;

  // Min et Max
  Result.Min := Timings[0];
  Result.Max := Timings[0];
  Sum := 0;

  for i := 0 to High(Timings) do
  begin
    if Timings[i] < Result.Min then Result.Min := Timings[i];
    if Timings[i] > Result.Max then Result.Max := Timings[i];
    Sum := Sum + Timings[i];
  end;

  // Moyenne
  Result.Mean := Sum / Length(Timings);

  // √âcart-type
  SumSquares := 0;
  for i := 0 to High(Timings) do
    SumSquares := SumSquares + Sqr(Timings[i] - Result.Mean);
  Result.StdDev := Sqrt(SumSquares / Length(Timings));

  // M√©diane
  SortedTimings := Copy(Timings);
  // Tri simple (bubble sort suffisant pour benchmarks)
  for i := 0 to High(SortedTimings) do
    for var j := 0 to High(SortedTimings) - i - 1 do
      if SortedTimings[j] > SortedTimings[j+1] then
      begin
        var Temp := SortedTimings[j];
        SortedTimings[j] := SortedTimings[j+1];
        SortedTimings[j+1] := Temp;
      end;

  Result.Median := SortedTimings[Length(SortedTimings) div 2];
end;

procedure RunBenchmarkWithStats(const Name: string; Proc: TBenchmarkProc;
                                Runs: Integer);
var
  Timings: array of QWord;
  Stats: TBenchmarkStats;
  SW: TStopwatch;
  i: Integer;
begin
  SetLength(Timings, Runs);
  SW := TStopwatch.Create;

  try
    WriteLn('Benchmark : ', Name);
    WriteLn('Runs : ', Runs);

    for i := 0 to Runs-1 do
    begin
      SW.Reset;
      SW.Start;
      Proc();
      SW.Stop;
      Timings[i] := SW.ElapsedMilliseconds;
    end;

    Stats := CalculateStats(Timings);

    WriteLn('R√©sultats :');
    WriteLn('  Min     : ', Stats.Min, ' ms');
    WriteLn('  Max     : ', Stats.Max, ' ms');
    WriteLn('  Moyenne : ', FormatFloat('0.00', Stats.Mean), ' ms');
    WriteLn('  M√©diane : ', Stats.Median, ' ms');
    WriteLn('  √âcart-œÉ : ', FormatFloat('0.00', Stats.StdDev), ' ms');

    // Coefficient de variation (stabilit√©)
    var CV := (Stats.StdDev / Stats.Mean) * 100;
    WriteLn('  CV      : ', FormatFloat('0.00', CV), ' %');

    if CV < 5 then
      WriteLn('  ‚úì R√©sultats tr√®s stables')
    else if CV < 15 then
      WriteLn('  ‚ö† R√©sultats mod√©r√©ment stables')
    else
      WriteLn('  ‚úó R√©sultats instables - augmenter le nombre de runs');

  finally
    SW.Free;
  end;
end;
```

---

## Annexe D : Benchmarking R√©seau et I/O

Pour les op√©rations r√©seau et I/O, mesurez √©galement le throughput :

```pascal
type
  TNetworkBenchmark = class
  public
    class procedure BenchmarkFileIO(const FileName: string; SizeMB: Integer);
    class procedure BenchmarkNetworkSpeed(const URL: string);
  end;

class procedure TNetworkBenchmark.BenchmarkFileIO(const FileName: string;
                                                   SizeMB: Integer);
var
  F: File;
  Buffer: array[0..1023] of Byte;
  SW: TStopwatch;
  i, Iterations: Integer;
  ThroughputMBps: Double;
begin
  Iterations := SizeMB * 1024; // 1 KB par it√©ration

  SW := TStopwatch.Create;
  try
    // √âcriture
    AssignFile(F, FileName);
    Rewrite(F, 1);

    SW.Start;
    for i := 0 to Iterations-1 do
      BlockWrite(F, Buffer, SizeOf(Buffer));
    SW.Stop;

    CloseFile(F);

    ThroughputMBps := (SizeMB * 1000.0) / SW.ElapsedMilliseconds;

    WriteLn('√âcriture fichier :');
    WriteLn('  Taille     : ', SizeMB, ' MB');
    WriteLn('  Temps      : ', SW.ElapsedMilliseconds, ' ms');
    WriteLn('  Throughput : ', FormatFloat('0.00', ThroughputMBps), ' MB/s');

    // Lecture
    SW.Reset;
    Reset(F, 1);

    SW.Start;
    for i := 0 to Iterations-1 do
      BlockRead(F, Buffer, SizeOf(Buffer));
    SW.Stop;

    CloseFile(F);

    ThroughputMBps := (SizeMB * 1000.0) / SW.ElapsedMilliseconds;

    WriteLn('Lecture fichier :');
    WriteLn('  Taille     : ', SizeMB, ' MB');
    WriteLn('  Temps      : ', SW.ElapsedMilliseconds, ' ms');
    WriteLn('  Throughput : ', FormatFloat('0.00', ThroughputMBps), ' MB/s');

    // Nettoyage
    DeleteFile(FileName);

  finally
    SW.Free;
  end;
end;
```

---

## Annexe E : Comparaison Windows vs Ubuntu

Exemple de code qui compare automatiquement les performances sur les deux OS :

```pascal
program CrossPlatformBenchmark;

{$mode objfpc}{$H+}

uses
  SysUtils, DateUtils
  {$IFDEF WINDOWS}, Windows{$ENDIF}
  {$IFDEF UNIX}, Unix, BaseUnix{$ENDIF};

procedure PrintPlatformInfo;
begin
  WriteLn('‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó');
  WriteLn('‚ïë     BENCHMARK MULTI-PLATEFORME                         ‚ïë');
  WriteLn('‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù');
  WriteLn;

  {$IFDEF WINDOWS}
  WriteLn('Plateforme    : Windows');
  {$ENDIF}
  {$IFDEF UNIX}
  WriteLn('Plateforme    : Unix/Linux');
  {$ENDIF}

  WriteLn('Architecture  : ', {$I %FPCTARGETCPU%});
  WriteLn('Bits          : ', SizeOf(Pointer) * 8);
  WriteLn('Compilateur   : FPC ', {$I %FPCVERSION%});
  WriteLn('Date          : ', DateTimeToStr(Now));
  WriteLn;
end;

procedure BenchmarkStringOperations;
var
  SW: TStopwatch;
  i: Integer;
  S: string;
begin
  SW := TStopwatch.Create;
  try
    WriteLn('Test : Concat√©nation de cha√Ænes');

    SW.Start;
    S := '';
    for i := 1 to 10000 do
      S := S + 'X';
    SW.Stop;

    WriteLn('  Temps : ', SW.ElapsedMilliseconds, ' ms');
  finally
    SW.Free;
  end;
end;

procedure BenchmarkMathOperations;
var
  SW: TStopwatch;
  i: Integer;
  Sum: Double;
begin
  SW := TStopwatch.Create;
  try
    WriteLn('Test : Op√©rations math√©matiques');

    SW.Start;
    Sum := 0;
    for i := 1 to 1000000 do
      Sum := Sum + Sqrt(i) * Sin(i);
    SW.Stop;

    WriteLn('  Temps : ', SW.ElapsedMilliseconds, ' ms');
    WriteLn('  Total : ', FormatFloat('0.00', Sum));
  finally
    SW.Free;
  end;
end;

begin
  PrintPlatformInfo;
  BenchmarkStringOperations;
  WriteLn;
  BenchmarkMathOperations;
  WriteLn;
  WriteLn('Benchmark termin√©.');

  {$IFDEF WINDOWS}
  WriteLn('Appuyez sur Entr√©e...');
  ReadLn;
  {$ENDIF}
end.
```

---

## Ressources Compl√©mentaires

### Documentation officielle
- **FreePascal Wiki** : https://wiki.freepascal.org/Profiling
- **Lazarus Wiki** : https://wiki.lazarus.freepascal.org/Performance

### Outils recommand√©s

**Windows :**
- Intel VTune Profiler
- AMD ŒºProf
- Very Sleepy (profiler simple et gratuit)

**Ubuntu/Linux :**
- Valgrind (callgrind, cachegrind, massif)
- perf (Linux Performance Events)
- gperftools (Google Performance Tools)

### Livres et articles
- "Systems Performance" - Brendan Gregg
- "The Art of Computer Programming" - Donald Knuth (Vol. 1, Chapitre 1.3)

---

## Points Cl√©s √† Retenir

‚ú® **Le benchmarking est une science** qui n√©cessite rigueur et m√©thodologie

üî¨ **Mesurer, pas deviner** : Les intuitions sont souvent fausses

üìà **Automatiser** : Int√©grer les benchmarks dans votre CI/CD

üéØ **Cibler** : Optimiser l√† o√π √ßa compte vraiment (loi de Pareto)

‚öñÔ∏è **√âquilibrer** : Performance vs lisibilit√© vs maintenabilit√©

üåç **Tester sur les deux OS** : Les performances peuvent varier significativement

üìä **Documenter** : Vos r√©sultats sont pr√©cieux pour l'√©quipe

---

**Note finale :** Le benchmarking n'est pas une activit√© ponctuelle, mais un processus continu. Int√©grez-le dans votre workflow de d√©veloppement pour cr√©er des applications FreePascal/Lazarus rapides et efficaces sur Windows et Ubuntu !

**Prochaines √©tapes :**
- Identifier les parties critiques de votre application
- Mettre en place un framework de benchmarking
- Cr√©er une baseline de performance
- Optimiser progressivement
- Mesurer et documenter les am√©liorations

**Bonne optimisation ! üöÄ**

‚è≠Ô∏è [Optimisation pour diff√©rentes architectures](/20-optimisation-performance/10-optimisation-differentes-architectures.md)
