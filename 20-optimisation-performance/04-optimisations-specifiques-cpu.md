üîù Retour au [Sommaire](/SOMMAIRE.md)

# 20.4 Optimisations sp√©cifiques CPU

## Introduction

Les processeurs modernes sont des machines extr√™mement complexes qui utilisent de nombreuses techniques pour ex√©cuter le code le plus rapidement possible. Comprendre comment fonctionne le CPU permet d'√©crire du code qui exploite au mieux ces capacit√©s. Ce chapitre explore les optimisations sp√©cifiques au niveau du processeur, ind√©pendamment du langage de programmation utilis√©.

## Architecture du CPU moderne

### Pipeline d'instructions

Un processeur moderne ne traite pas les instructions une par une. Il utilise un **pipeline** pour ex√©cuter plusieurs instructions simultan√©ment √† diff√©rentes √©tapes.

**Pipeline simplifi√© (5 √©tapes)** :
```
1. FETCH    : Charger l'instruction depuis la m√©moire
2. DECODE   : D√©coder l'instruction
3. EXECUTE  : Ex√©cuter l'op√©ration
4. MEMORY   : Acc√©der √† la m√©moire (si n√©cessaire)
5. WRITEBACK: √âcrire le r√©sultat
```

**Exemple de pipeline en action** :
```
Cycle 1:  [Instr1: FETCH]
Cycle 2:  [Instr1: DECODE] [Instr2: FETCH]
Cycle 3:  [Instr1: EXEC  ] [Instr2: DECODE] [Instr3: FETCH]
Cycle 4:  [Instr1: MEMORY] [Instr2: EXEC  ] [Instr3: DECODE] [Instr4: FETCH]
Cycle 5:  [Instr1: WRITE ] [Instr2: MEMORY] [Instr3: EXEC  ] [Instr4: DECODE] [Instr5: FETCH]
```

Dans un pipeline parfait, une instruction se termine √† chaque cycle, m√™me si chaque instruction prend 5 cycles au total.

**IPC (Instructions Per Cycle)** :
- Pipeline id√©al : IPC = 1.0 (une instruction par cycle)
- Processeurs modernes : IPC = 2.0 - 4.0 (superscalaire)
- Pipeline avec probl√®mes : IPC < 1.0

### Ex√©cution superscalaire

Les CPU modernes peuvent ex√©cuter **plusieurs instructions par cycle** gr√¢ce √† plusieurs unit√©s d'ex√©cution :

```
CPU moderne :
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  2 unit√©s enti√®res (ALU)            ‚îÇ
‚îÇ  2 unit√©s FPU (float/double)        ‚îÇ
‚îÇ  2 unit√©s Load/Store (m√©moire)      ‚îÇ
‚îÇ  1 unit√© de branchement             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Peut ex√©cuter jusqu'√† 4-6 instructions par cycle
```

**Exemple** :
```pascal
// Ces 4 instructions peuvent s'ex√©cuter en parall√®le
A := B + C;    // ALU #1
D := E + F;    // ALU #2
X := Y * 2.0;  // FPU #1
Load(Z);       // Load/Store
```

### Ex√©cution dans le d√©sordre (Out-of-Order)

Le CPU peut r√©organiser les instructions pour maximiser l'utilisation du pipeline :

```pascal
// Code √©crit :
A := LoadFromMemory();  // 200 cycles (lent)
B := C + D;             // 1 cycle (rapide)
E := A + 1;             // D√©pend de A

// Ex√©cution r√©elle par le CPU :
// 1. Lancer LoadFromMemory() (asynchrone)
// 2. Ex√©cuter B := C + D (pendant que A charge)
// 3. Attendre A
// 4. Ex√©cuter E := A + 1
```

Le CPU r√©ordonne automatiquement pour √©viter que `B := C + D` attende inutilement.

## Branch Prediction (Pr√©diction de branchement)

### Qu'est-ce qu'un branchement ?

Un **branchement** est un `if`, `while`, `for`, ou tout code qui peut prendre diff√©rents chemins :

```pascal
if X > 10 then    // ‚Üê Branchement
  DoA()
else
  DoB();
```

### Pourquoi c'est un probl√®me ?

Le CPU ne sait pas quel chemin sera pris avant d'√©valuer la condition. En attendant, le pipeline se vide :

```
Sans pr√©diction :
Cycle 1-5  : √âvaluer condition (X > 10)
Cycle 6    : Pipeline vide (stall)
Cycle 7    : Commencer DoA() ou DoB()

Perte : ~10-20 cycles par branchement rat√©
```

### Branch Predictor (Pr√©dicteur de branchement)

Le CPU **devine** quel chemin sera pris et commence √† l'ex√©cuter de mani√®re sp√©culative :

```
Avec pr√©diction correcte :
Cycle 1-5  : √âvaluer condition + ex√©cuter DoA() (sp√©culatif)
Cycle 6    : Confirmer pr√©diction ‚Üí Continuer
Perte : 0 cycle

Avec pr√©diction incorrecte :
Cycle 1-5  : √âvaluer condition + ex√©cuter DoA() (sp√©culatif)
Cycle 6    : Pr√©diction fausse ‚Üí Annuler + d√©marrer DoB()
Perte : ~15-20 cycles
```

### Types de pr√©dicteurs

**1. Pr√©dicteur statique** : Toujours pr√©dire "pris" ou "jamais pris"
```pascal
// Pr√©dit "jamais pris"
if RareCondition then  // Presque toujours false
  HandleError();
// Bonne pr√©diction 99% du temps
```

**2. Pr√©dicteur dynamique** : Apprendre des ex√©cutions pass√©es

**Exemple : Compteur √† saturation**
```
√âtat initial : 00 (fortement pas pris)
           ‚Üì
00 ‚Üí 01 ‚Üí 10 ‚Üí 11 (fortement pris)
 ‚Üë              ‚Üì
  ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
```

```pascal
// Pattern pr√©visible
for i := 1 to 100 do
begin
  if i mod 2 = 0 then  // Alterne vrai/faux
    DoEven()
  else
    DoOdd();
end;
// Le pr√©dicteur apprend le pattern ‚Üí ~95% de pr√©cision
```

### Taux de pr√©diction

**Performances** :
- **> 95%** de pr√©cision : Excellent (code pr√©visible)
- **85-95%** : Bon (code avec quelques branches difficiles)
- **< 85%** : Mauvais (code impr√©visible, ralentit significativement)

**Mesurer** :
```bash
# Linux avec perf
perf stat -e branches,branch-misses ./programme

# Exemple de sortie :
#   12,345,678  branches
#      456,789  branch-misses  # 3.7% miss rate (excellent)
```

### Optimiser pour la pr√©diction de branchement

#### ‚ùå Code impr√©visible (mauvais)

```pascal
// Pattern al√©atoire ‚Üí 50% de mispredictions
for i := 0 to 1000000 do
begin
  if Random(2) = 0 then
    ProcessA(Data[i])
  else
    ProcessB(Data[i]);
end;

// Temps : ~150 ms
// Branch miss rate : 50% (tr√®s mauvais)
```

#### ‚úÖ Code pr√©visible (bon)

**Technique 1 : √âliminer le branchement**
```pascal
// Utiliser des op√©rations arithm√©tiques au lieu de if
function Max(A, B: Integer): Integer;
begin
  // ‚ùå Avec branchement
  if A > B then
    Result := A
  else
    Result := B;
end;

function MaxOptimized(A, B: Integer): Integer;
begin
  // ‚úÖ Sans branchement (branchless)
  Result := A + ((B - A) and (Integer(B > A) - 1));
  // ou utiliser l'instruction CMOV sur x86
end;
```

**Technique 2 : Trier avant de traiter**
```pascal
type
  TItem = record
    Value: Integer;
    ShouldProcess: Boolean;
  end;

var
  Items: array of TItem;
  i: Integer;

// ‚ùå Branchements impr√©visibles
for i := 0 to High(Items) do
  if Items[i].ShouldProcess then  // Pattern al√©atoire
    Process(Items[i]);

// ‚úÖ Trier d'abord, puis traiter
SortItemsByShouldProcess(Items);  // Tous les True ensemble
for i := 0 to High(Items) do
  if Items[i].ShouldProcess then  // Pattern pr√©visible
    Process(Items[i])
  else
    Break;  // Sortir quand on atteint les False

// Gain : 2x √† 3x plus rapide si beaucoup d'√©l√©ments
```

**Technique 3 : Utiliser des tables de lookup**
```pascal
// ‚ùå Beaucoup de branchements
function GetCategory(Value: Integer): string;
begin
  if Value < 10 then
    Result := 'Low'
  else if Value < 50 then
    Result := 'Medium'
  else if Value < 100 then
    Result := 'High'
  else
    Result := 'Very High';
end;

// ‚úÖ Table de lookup (sans branchement)
const
  CategoryTable: array[0..100] of string = (
    // 0-9: Low
    'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low',
    // 10-49: Medium
    'Medium', 'Medium', ...,
    // 50-99: High
    'High', 'High', ...,
    // 100: Very High
    'Very High'
  );

function GetCategoryOptimized(Value: Integer): string;
begin
  if Value > 100 then Value := 100;
  if Value < 0 then Value := 0;
  Result := CategoryTable[Value];
end;
```

**Technique 4 : Utiliser CMOV (Conditional Move)**
```pascal
{$ASMMODE INTEL}

function MinBranchless(A, B: Integer): Integer;
asm
  mov eax, A
  mov edx, B
  cmp eax, edx
  cmovg eax, edx  // Move si greater (branchless)
end;

// CMOV ex√©cute toujours en 1 cycle, pas de pipeline flush
```

## Cache et hi√©rarchie m√©moire

### Principe de localit√©

**Localit√© temporelle** : Une donn√©e r√©cemment acc√©d√©e sera probablement r√©utilis√©e bient√¥t.
**Localit√© spatiale** : Les donn√©es voisines seront probablement acc√©d√©es ensemble.

```pascal
// ‚úÖ Bonne localit√© spatiale
var
  Data: array[0..9999] of Integer;
  i: Integer;
begin
  for i := 0 to 9999 do
    Process(Data[i]);  // Acc√®s s√©quentiel
end;
// Temps : ~5 ms

// ‚ùå Mauvaise localit√© spatiale
begin
  for i := 0 to 9999 do
    Process(Data[Random(10000)]);  // Acc√®s al√©atoire
end;
// Temps : ~80 ms (16x plus lent !)
```

### Cache Line (Ligne de cache)

Le cache charge la m√©moire par blocs de **64 bytes** (ligne de cache) :

```pascal
type
  TData = record
    A: Integer;  // Offset 0
    B: Integer;  // Offset 4
  end;

var
  Data: TData;

// Acc√©der √† Data.A charge toute la ligne de cache (64 bytes)
// ‚Üí Data.B est d√©j√† en cache (gratuit)
X := Data.A;
Y := Data.B;  // Presque instantan√© (cache hit)
```

### False Sharing (Partage factice)

**Probl√®me en multi-threading** :

```pascal
type
  TCounter = record
    Value: Int64;  // 8 bytes
  end;

var
  Counters: array[0..7] of TCounter;  // 8 threads

// Thread 1 modifie Counters[0]
// Thread 2 modifie Counters[1]
// Probl√®me : Les deux sont dans la M√äME ligne de cache (64 bytes)
// ‚Üí Chaque modification invalide le cache de l'autre thread
```

**Solution : Padding**
```pascal
type
  TCounter = record
    Value: Int64;
    Padding: array[0..6] of Int64;  // Force 64 bytes
  end align 64;

var
  Counters: array[0..7] of TCounter;
// Maintenant chaque compteur est dans sa propre ligne de cache
```

### Prefetching (Pr√©chargement)

Le CPU essaie de deviner quelles donn√©es seront n√©cessaires et les charge en avance.

**Prefetch automatique** :
```pascal
// Pattern s√©quentiel ‚Üí Prefetcher d√©tecte et charge en avance
for i := 0 to 1000000 do
  Sum := Sum + Data[i];
// Le CPU charge Data[i+10] pendant qu'il traite Data[i]
```

**Prefetch manuel** :
```pascal
{$ASMMODE INTEL}

procedure ProcessWithPrefetch(Data: PInteger; Count: Integer);
var i: Integer;
begin
  for i := 0 to Count - 1 do
  begin
    // Prefetch manuel 64 √©l√©ments √† l'avance
    if i + 64 < Count then
      asm
        mov rax, Data
        lea rax, [rax + (i + 64) * 4]
        prefetchnta [rax]
      end;

    Process(Data[i]);
  end;
end;
```

**Types de prefetch** :
- `prefetchnta` : Non-temporal (ne pollue pas le cache L3)
- `prefetcht0` : Vers tous les niveaux de cache
- `prefetcht1` : Vers L2/L3
- `prefetcht2` : Vers L3 uniquement

## Optimisations sp√©cifiques aux architectures

### x86/x64 (Intel/AMD)

#### Registres et conventions

**Registres 64-bit** :
```
RAX, RBX, RCX, RDX : Registres g√©n√©raux
RSI, RDI           : Source/Destination
RBP, RSP           : Base/Stack pointer
R8-R15             : Registres additionnels (x64)
```

**Registres SIMD** :
```
XMM0-XMM15 : 128 bits (SSE)
YMM0-YMM15 : 256 bits (AVX)
ZMM0-ZMM31 : 512 bits (AVX-512)
```

#### Instructions sp√©cifiques Intel

**BSF/BSR** : Bit Scan Forward/Reverse
```pascal
{$ASMMODE INTEL}

function FindFirstSetBit(Value: QWord): Integer;
// Trouve la position du premier bit √† 1
asm
  bsf rax, Value
  jnz @Found
  mov rax, -1  // Aucun bit trouv√©
@Found:
end;
// Temps : 3 cycles (vs ~20 cycles en boucle)
```

**POPCNT** : Population Count (nombre de bits √† 1)
```pascal
function CountBits(Value: QWord): Integer;
asm
  popcnt rax, Value
end;
// Temps : 3 cycles (vs ~64 cycles en boucle)
```

**LZCNT** : Leading Zero Count
```pascal
function LeadingZeros(Value: QWord): Integer;
asm
  lzcnt rax, Value
end;
```

**BMI/BMI2** : Bit Manipulation Instructions
```pascal
// ANDN: AND NOT
function AndNot(A, B: QWord): QWord;
asm
  mov rax, A
  andn rax, rax, B  // rax = A AND (NOT B)
end;

// BZHI: Zero high bits
function ZeroHighBits(Value: QWord; Index: Byte): QWord;
asm
  mov rax, Value
  mov cl, Index
  bzhi rax, rax, rcx  // Mettre √† 0 les bits >= Index
end;
```

#### Optimisations de cache Intel

**Cache Associativity** :
- L1: 8-way set associative
- L2: 4-way
- L3: 16-way

**Optimisation** : √âviter les conflits d'associativit√©
```pascal
// ‚ùå Mauvais : Stride de 4096 (taille page)
// Cause des conflits de cache
for i := 0 to 999 do
  Access(Data[i * 4096]);

// ‚úÖ Bon : Stride diff√©rent
for i := 0 to 999 do
  Access(Data[i * 4097]);  // Prime avec 4096
```

### ARM (Raspberry Pi, mobiles)

#### Registres ARM64

```
X0-X30  : Registres g√©n√©raux 64-bit
W0-W30  : Registres 32-bit (moiti√© basse de X0-X30)
SP      : Stack Pointer
PC      : Program Counter
V0-V31  : Registres NEON/FPU (128-bit)
```

#### Instructions ARM sp√©cifiques

**Barrel Shifter** : D√©calage gratuit
```pascal
// Sur ARM, le d√©calage ne co√ªte rien s'il est combin√©
A := B + (C shl 2);  // 1 cycle (d√©calage gratuit)

// √âquivalent en ARM assembly :
// ADD X0, X1, X2, LSL #2
```

**Conditional Execution** : Presque toutes les instructions peuvent √™tre conditionnelles
```asm
CMP X0, X1
ADDGT X2, X3, X4  // ADD si Greater Than (pas de branchement!)
```

**NEON (SIMD ARM)** :
```pascal
// Voir section 20.3 pour d√©tails NEON
```

### Diff√©rences AMD vs Intel

| Caract√©ristique | Intel | AMD (Zen 3+) |
|-----------------|-------|--------------|
| **Pipeline** | 14+ √©tages | 10+ √©tages |
| **Cache L3** | Partag√© | Par CCX (chiplet) |
| **Latence m√©moire** | ~70ns | ~60-80ns selon CCX |
| **AVX-512** | Oui (Ice Lake+) | Non (sauf Zen 4+) |
| **SMT** | Hyper-Threading | SMT |
| **Optimisations** | ¬µop cache | Op cache |

**Code qui performe diff√©remment** :
```pascal
// Calcul intensif avec beaucoup de branchements
// ‚Üí Intel g√©n√©ralement plus rapide (meilleur predicteur)

// Calcul parall√®le multi-thread√©
// ‚Üí AMD comp√©titif ou plus rapide (plus de c≈ìurs)

// AVX-512
// ‚Üí Intel beaucoup plus rapide (AMD n'a pas AVX-512 avant Zen 4)
```

## Optimisations du compilateur FreePascal

### Options de compilation

```bash
# Optimisations de base
fpc -O1 programme.pas
# - √âlimination du code mort
# - Propagation de constantes

# Optimisations standards (recommand√©)
fpc -O2 programme.pas
# - Tout de -O1
# - Loop unrolling (d√©roulement de boucles)
# - Inline de fonctions
# - R√©ordonnancement d'instructions

# Optimisations agressives
fpc -O3 programme.pas
# - Tout de -O2
# - Vectorisation automatique
# - Optimisations plus agressives

# Optimisation pour taille
fpc -Os programme.pas
# - R√©duire la taille du code
```

### Optimisations sp√©cifiques CPU

```bash
# Generic x86-64
fpc -O3 -Px86_64 programme.pas

# Intel Core (Sandy Bridge+)
fpc -O3 -CpCOREI -CfAVX programme.pas

# Intel Core (Haswell+, avec AVX2)
fpc -O3 -CpCOREAVX2 -CfAVX2 programme.pas

# AMD Ryzen
fpc -O3 -CpZEN -CfAVX2 programme.pas

# ARM Cortex-A53 (Raspberry Pi 3)
fpc -O3 -CpARMV8 programme.pas

# ARM Cortex-A72 (Raspberry Pi 4)
fpc -O3 -CpARMV8 -CfVFPV4 programme.pas
```

### Inline et d√©roulement de boucles

**Inline de fonctions** :
```pascal
function Square(X: Integer): Integer; inline;
begin
  Result := X * X;
end;

// Le compilateur remplace l'appel par le code directement
Y := Square(5);  // Devient : Y := 5 * 5;
```

**D√©roulement de boucles** :
```pascal
// Code source
for i := 0 to 99 do
  A[i] := i;

// Code g√©n√©r√© avec -O3 (loop unrolling)
i := 0;
while i <= 96 do
begin
  A[i] := i;
  A[i+1] := i+1;
  A[i+2] := i+2;
  A[i+3] := i+3;  // 4 it√©rations par boucle
  Inc(i, 4);
end;
// Traiter les 3 derniers √©l√©ments
while i <= 99 do
begin
  A[i] := i;
  Inc(i);
end;
```

**B√©n√©fices** :
- Moins d'overhead de boucle
- Meilleure utilisation du pipeline
- Permet la vectorisation SIMD

## Techniques d'optimisation avanc√©es

### 1. Software Pipelining

R√©organiser le code pour maximiser le parall√©lisme :

```pascal
// ‚ùå Version non optimis√©e
for i := 0 to N - 1 do
begin
  A := Load(i);      // 200 cycles
  B := Process(A);   // 10 cycles (attend A)
  Store(i, B);       // 5 cycles (attend B)
end;
// Total : N √ó 215 cycles

// ‚úÖ Version avec software pipelining
A0 := Load(0);  // Pr√©charger
for i := 0 to N - 2 do
begin
  A1 := Load(i + 1);     // Charger le suivant
  B0 := Process(A0);     // Traiter le courant (pendant que A1 charge)
  Store(i, B0);          // Stocker le courant
  A0 := A1;              // Pr√©parer l'it√©ration suivante
end;
B0 := Process(A0);
Store(N - 1, B0);
// Total : N √ó 200 cycles (10% plus rapide)
```

### 2. Loop Fusion (Fusion de boucles)

Combiner plusieurs boucles pour am√©liorer la localit√© de cache :

```pascal
// ‚ùå Deux boucles s√©par√©es
for i := 0 to N - 1 do
  A[i] := B[i] + 1;

for i := 0 to N - 1 do
  C[i] := A[i] * 2;

// ‚úÖ Boucle fusionn√©e
for i := 0 to N - 1 do
begin
  A[i] := B[i] + 1;
  C[i] := A[i] * 2;
end;
// Gain : Meilleure utilisation du cache L1
```

### 3. Loop Interchange (Permutation de boucles)

R√©organiser les boucles imbriqu√©es pour un meilleur acc√®s m√©moire :

```pascal
// ‚ùå Mauvais : Acc√®s par colonnes (cache miss)
for i := 0 to Rows - 1 do
  for j := 0 to Cols - 1 do
    Matrix[j][i] := 0;  // Stride = Cols (mauvais)

// ‚úÖ Bon : Acc√®s par lignes (cache-friendly)
for i := 0 to Cols - 1 do
  for j := 0 to Rows - 1 do
    Matrix[i][j] := 0;  // Stride = 1 (bon)

// Gain : 5x √† 10x plus rapide pour grandes matrices
```

### 4. Loop Tiling (D√©coupage en blocs)

D√©couper les grandes boucles en blocs qui tiennent dans le cache :

```pascal
const
  TileSize = 64;  // Taille optimale pour cache L1

// ‚ùå Sans tiling (cache thrashing)
for i := 0 to N - 1 do
  for j := 0 to N - 1 do
    C[i, j] := A[i, j] + B[i, j];

// ‚úÖ Avec tiling
for ii := 0 to (N - 1) div TileSize do
  for jj := 0 to (N - 1) div TileSize do
    for i := ii * TileSize to Min((ii + 1) * TileSize - 1, N - 1) do
      for j := jj * TileSize to Min((jj + 1) * TileSize - 1, N - 1) do
        C[i, j] := A[i, j] + B[i, j];

// Gain : 2x √† 3x plus rapide pour N > 1000
```

### 5. Strength Reduction

Remplacer les op√©rations co√ªteuses par des op√©rations plus rapides :

```pascal
// ‚ùå Multiplication dans la boucle
for i := 0 to N - 1 do
  A[i] := i * 7;

// ‚úÖ Addition incr√©mentale
Value := 0;
for i := 0 to N - 1 do
begin
  A[i] := Value;
  Value := Value + 7;  // Addition au lieu de multiplication
end;
```

## Profiling au niveau CPU

### Compteurs de performance (PMU)

Les CPUs modernes ont des compteurs mat√©riels pour mesurer :
- Instructions ex√©cut√©es
- Cycles d'horloge
- Cache hits/misses
- Branch mispredictions
- Stalls de pipeline

**Linux (perf)** :
```bash
# Compteurs de base
perf stat ./programme

# Compteurs sp√©cifiques
perf stat -e cycles,instructions,cache-references,cache-misses,branches,branch-misses ./programme

# Exemple de sortie :
#   987,654,321  cycles
#   1,234,567,890  instructions  # IPC = 1.25
#   12,345,678  cache-references
#      456,789  cache-misses      # 3.7% miss rate
#   234,567,890  branches
#      5,678,901  branch-misses   # 2.4% miss rate
```

**Windows (Intel VTune)** :
- Microarchitecture Exploration
- Memory Access Analysis
- Branch Analysis

### Interpr√©ter les m√©triques

**IPC (Instructions Per Cycle)** :
- IPC > 2.0 : Excellent (code bien optimis√©)
- IPC 1.0-2.0 : Bon √† correct
- IPC < 1.0 : Mauvais (beaucoup de stalls)

**Cache Miss Rate** :
- < 1% : Excellent
- 1-5% : Bon
- 5-10% : Moyen
- > 10% : Mauvais

**Branch Miss Rate** :
- < 2% : Excellent
- 2-5% : Bon
- 5-10% : Moyen
- > 10% : Mauvais

## Optimisations multi-plateformes

### Code adaptatif selon le CPU

```pascal
unit CPUOptimized;

interface

type
  TProcessFunc = procedure(Data: Pointer; Size: Integer);

var
  ProcessData: TProcessFunc;  // Pointeur vers la meilleure impl√©mentation

implementation

uses
  CPUFeatures;  // D√©tection des capacit√©s (voir section 20.3)

procedure ProcessScalar(Data: Pointer; Size: Integer);
begin
  // Impl√©mentation de base
end;

procedure ProcessSSE(Data: Pointer; Size: Integer);
begin
  // Impl√©mentation SSE
end;

procedure ProcessAVX2(Data: Pointer; Size: Integer);
begin
  // Impl√©mentation AVX2
end;

procedure ProcessNEON(Data: Pointer; Size: Integer);
begin
  // Impl√©mentation ARM NEON
end;

initialization
  // S√©lectionner la meilleure impl√©mentation au d√©marrage
  {$IFDEF CPUX64}
  var Features := DetectCPUFeatures;

  if Features.HasAVX2 then
    ProcessData := @ProcessAVX2
  else if Features.HasSSE41 then
    ProcessData := @ProcessSSE
  else
    ProcessData := @ProcessScalar;
  {$ENDIF}

  {$IFDEF CPUARM}
  if HasNEON then
    ProcessData := @ProcessNEON
  else
    ProcessData := @ProcessScalar;
  {$ENDIF}

  {$IF NOT DEFINED(CPUX64) AND NOT DEFINED(CPUARM)}
  ProcessData := @ProcessScalar;
  {$ENDIF}
end.
```

### Directives de compilation conditionnelle

```pascal
procedure OptimizedFunction;
begin
  {$IFDEF CPUX64}
    {$IF DEFINED(CPUAVX2)}
    // Code AVX2
    ProcessAVX2();
    {$ELSEIF DEFINED(CPUSSE41)}
    // Code SSE4.1
    ProcessSSE();
    {$ELSE}
    // Code x64 g√©n√©rique
    ProcessX64();
    {$ENDIF}
  {$ENDIF}

  {$IFDEF CPUARM}
    {$IFDEF CPUNEON}
    // Code NEON
    ProcessNEON();
    {$ELSE}
    // Code ARM g√©n√©rique
    ProcessARM();
    {$ENDIF}
  {$ENDIF}

  {$IF NOT DEFINED(CPUX64) AND NOT DEFINED(CPUARM)}
    // Code portable par d√©faut
    ProcessScalar();
  {$ENDIF}
end;
```

### Macros pour code multi-architecture

```pascal
// Fichier: platform_macros.inc

{$IFDEF CPUX64}
  {$DEFINE HAS_FAST_MULTIPLY}
  {$DEFINE HAS_64BIT_INTEGERS}
  {$DEFINE CACHE_LINE_SIZE := 64}
{$ENDIF}

{$IFDEF CPUARM}
  {$DEFINE HAS_BARREL_SHIFTER}
  {$IFDEF CPUARM64}
    {$DEFINE HAS_64BIT_INTEGERS}
  {$ENDIF}
  {$DEFINE CACHE_LINE_SIZE := 64}
{$ENDIF}

{$IFDEF CPUI386}
  {$DEFINE CACHE_LINE_SIZE := 64}
{$ENDIF}

// Utilisation dans le code
{$I platform_macros.inc}

procedure AlignedAlloc;
var
  Data: Pointer;
begin
  {$IFDEF HAS_64BIT_INTEGERS}
  Data := GetMem(1024 * 1024);  // 1 MB
  {$ELSE}
  Data := GetMem(512 * 1024);   // 512 KB (32-bit limit√©)
  {$ENDIF}
end;
```

## Pi√®ges et anti-patterns

### 1. Fausse d√©pendance de donn√©es

```pascal
// ‚ùå Fausse d√©pendance : r√©utilisation de variable
var
  Temp: Integer;
begin
  Temp := A + B;
  Result1 := Temp * 2;
  Temp := C + D;      // R√©utilise Temp (d√©pendance artificielle)
  Result2 := Temp * 3;
end;
// Le CPU doit attendre que Result1 soit calcul√©

// ‚úÖ Pas de fausse d√©pendance
var
  Temp1, Temp2: Integer;
begin
  Temp1 := A + B;
  Temp2 := C + D;     // Peut s'ex√©cuter en parall√®le
  Result1 := Temp1 * 2;
  Result2 := Temp2 * 3;
end;
```

### 2. √âcriture partielle de registre

```pascal
{$ASMMODE INTEL}

// ‚ùå Mauvais : √©criture partielle (p√©nalit√©)
procedure BadPartialWrite;
asm
  mov eax, [Data]   // √âcrit 32-bit
  mov al, 5         // √âcrit 8-bit bas ‚Üí p√©nalit√©!
  mov [Result], eax
end;
// P√©nalit√© : ~5 cycles de stall

// ‚úÖ Bon : √©criture compl√®te
procedure GoodFullWrite;
asm
  xor eax, eax      // Mettre √† z√©ro d'abord
  mov al, 5         // Maintenant OK
  mov [Result], eax
end;
```

### 3. Instruction lentes

Certaines instructions sont beaucoup plus lentes que d'autres :

| Instruction | Cycles | Alternative |
|-------------|--------|-------------|
| `DIV` (division) | 20-40 | Multiplication par inverse |
| `IDIV` (division sign√©e) | 25-50 | Shift si puissance de 2 |
| `MUL` (64-bit) | 3-5 | √âviter si possible |
| `IMUL` (32-bit) | 3 | OK |
| `SQRT` | 10-15 | LUT ou approximation |
| `FPU DIV/SQRT` | 15-25 | SSE est plus rapide |

```pascal
// ‚ùå Division lente
Result := Value div 16;  // ~30 cycles

// ‚úÖ Shift (puissance de 2)
Result := Value shr 4;   // 1 cycle

// ‚ùå Division par constante non-puissance de 2
Result := Value div 10;  // ~30 cycles

// ‚úÖ Multiplication magique (compilateur peut optimiser)
// Manuellement : Result := (Value * 0xCCCCCCCD) shr 35;
Result := Value div 10;  // Avec -O3, optimis√© automatiquement
```

### 4. Latence vs Throughput

**Latence** : Temps pour une op√©ration seule
**Throughput** : Nombre d'op√©rations par cycle

```pascal
// Addition enti√®re :
// Latence = 1 cycle
// Throughput = 3-4 ops/cycle (plusieurs ALU)

// Division enti√®re :
// Latence = 30 cycles
// Throughput = 0.05 ops/cycle (1 divider)

// ‚ùå D√©pendance de latence
A := X div Y;  // 30 cycles
B := A + 1;    // Attend A (stall de 30 cycles)

// ‚úÖ Pas de d√©pendance
A := X div Y;  // 30 cycles
B := Z + 1;    // Ex√©cute en parall√®le (pas de d√©pendance)
C := A + 1;    // Attend A, mais B est d√©j√† fait
```

### 5. Alignement et acc√®s atomiques

```pascal
// ‚ùå Non align√© (peut √™tre lent ou crasher)
type
  TData = packed record
    Flag: Byte;
    Value: Int64;  // Non align√© sur 8 bytes!
  end;

var
  D: TData;
begin
  D.Value := 123;  // Acc√®s non align√© (lent ou crash)
end;

// ‚úÖ Align√©
type
  TData = record
    Flag: Byte;
    Padding: array[0..6] of Byte;
    Value: Int64;  // Align√© sur 8 bytes
  end;

// Ou utiliser align
type
  TData = record
    Value: Int64;
  end align 8;
```

## Techniques sp√©cifiques par domaine

### 1. Calcul intensif

**Optimisations** :
- Utiliser FMA (Fused Multiply-Add) si disponible
- √âviter les divisions (utiliser la multiplication par l'inverse)
- Vectoriser avec SIMD (voir section 20.3)
- Minimiser les conversions float ‚Üî int

```pascal
{$ASMMODE INTEL}

// ‚ùå Division en boucle
for i := 0 to N - 1 do
  Result[i] := Data[i] / Divisor;

// ‚úÖ Multiplication par inverse
var
  InvDivisor: Single;
begin
  InvDivisor := 1.0 / Divisor;  // Une division
  for i := 0 to N - 1 do
    Result[i] := Data[i] * InvDivisor;  // N multiplications
end;
// Gain : 5x √† 10x plus rapide
```

### 2. Traitement de cha√Ænes

**Optimisations** :
- Utiliser des op√©rations SIMD pour recherche/comparaison
- √âviter les copies inutiles
- Pr√©allouer les buffers

```pascal
{$ASMMODE INTEL}

// Recherche de caract√®re avec SSE2
function FindCharSSE2(const S: String; C: Char): Integer;
var
  P: PChar;
  Len, i: Integer;
  CharVec: array[0..15] of Char;
begin
  Result := 0;
  Len := Length(S);
  if Len = 0 then Exit;

  // Remplir un vecteur avec le caract√®re recherch√©
  for i := 0 to 15 do
    CharVec[i] := C;

  P := PChar(S);
  i := 0;

  // Traiter par blocs de 16 caract√®res
  while i + 16 <= Len do
  begin
    asm
      mov rax, P
      add rax, i

      movdqu xmm0, [rax]        // Charger 16 chars
      movdqu xmm1, CharVec      // Charger le pattern

      pcmpeqb xmm0, xmm1        // Comparer (0xFF si √©gal)
      pmovmskb eax, xmm0        // Extraire le masque

      test eax, eax
      jz @NotFound

      // Trouv√© : calculer la position
      bsf eax, eax              // Position du premier bit
      add eax, i
      mov Result, eax
      jmp @Done

    @NotFound:
    end;

    Inc(i, 16);
  end;

  // Traiter les caract√®res restants
  while i < Len do
  begin
    if P[i] = C then
    begin
      Result := i + 1;  // Position (base 1)
      Exit;
    end;
    Inc(i);
  end;

@Done:
end;
// Gain : 8x √† 16x plus rapide que Pos()
```

### 3. Compression/D√©compression

**Optimisations** :
- Utiliser les instructions BMI/BMI2 pour manipulation de bits
- SIMD pour traitement par blocs
- Tables de lookup pour Huffman

```pascal
// Comptage de bits avec POPCNT
function CountSetBits(Value: QWord): Integer;
asm
  {$IFDEF CPUPOPCNT}
  popcnt rax, Value
  {$ELSE}
  // Fallback sans POPCNT
  mov rax, Value
  mov rcx, rax
  shr rax, 1
  and rax, 0x5555555555555555
  sub rcx, rax
  mov rax, rcx
  shr rcx, 2
  and rax, 0x3333333333333333
  and rcx, 0x3333333333333333
  add rax, rcx
  mov rcx, rax
  shr rax, 4
  add rax, rcx
  and rax, 0x0F0F0F0F0F0F0F0F
  imul rax, rax, 0x0101010101010101
  shr rax, 56
  {$ENDIF}
end;
```

### 4. Cryptographie

**Optimisations** :
- Utiliser AES-NI pour AES
- Utiliser SHA extensions pour SHA-1/SHA-256
- √âviter les branches (timing attacks)
- Op√©rations en temps constant

```pascal
{$ASMMODE INTEL}

// AES avec instructions AES-NI
procedure AESEncryptBlockNI(const Key, Input: array of Byte; var Output: array of Byte);
asm
  mov rax, Key
  mov rdx, Input
  mov rcx, Output

  movdqu xmm0, [rdx]          // Charger le plaintext
  movdqu xmm1, [rax]          // Charger la cl√© de round 0

  pxor xmm0, xmm1             // Whitening

  // 10 rounds pour AES-128
  movdqu xmm1, [rax + 16]
  aesenc xmm0, xmm1           // Round 1

  movdqu xmm1, [rax + 32]
  aesenc xmm0, xmm1           // Round 2

  // ... rounds 3-9 ...

  movdqu xmm1, [rax + 160]
  aesenclast xmm0, xmm1       // Round 10 (final)

  movdqu [rcx], xmm0          // Stocker le ciphertext
end;
// Gain : 5x √† 10x plus rapide que impl√©mentation pure Pascal
```

## Benchmarking et validation

### Template de benchmark CPU

```pascal
program CPUBenchmark;

{$MODE OBJFPC}{$H+}
{$ASMMODE INTEL}

uses
  SysUtils, DateUtils;

const
  Iterations = 10000000;

var
  StartTime: TDateTime;
  ElapsedMs: Int64;
  A, B, C: Int64;

procedure BenchmarkAddition;
var i: Integer;
begin
  StartTime := Now;
  for i := 1 to Iterations do
    C := A + B;
  ElapsedMs := MilliSecondsBetween(Now, StartTime);
  WriteLn('Addition:         ', ElapsedMs, ' ms');
end;

procedure BenchmarkMultiplication;
var i: Integer;
begin
  StartTime := Now;
  for i := 1 to Iterations do
    C := A * B;
  ElapsedMs := MilliSecondsBetween(Now, StartTime);
  WriteLn('Multiplication:   ', ElapsedMs, ' ms');
end;

procedure BenchmarkDivision;
var i: Integer;
begin
  StartTime := Now;
  for i := 1 to Iterations do
    C := A div B;
  ElapsedMs := MilliSecondsBetween(Now, StartTime);
  WriteLn('Division:         ', ElapsedMs, ' ms');
end;

procedure BenchmarkBitShift;
var i: Integer;
begin
  StartTime := Now;
  for i := 1 to Iterations do
    C := A shr 4;
  ElapsedMs := MilliSecondsBetween(Now, StartTime);
  WriteLn('Bit Shift:        ', ElapsedMs, ' ms');
end;

procedure BenchmarkBranchPredictable;
var i: Integer;
begin
  StartTime := Now;
  for i := 1 to Iterations do
  begin
    if i mod 2 = 0 then  // Pattern pr√©visible
      C := A + B
    else
      C := A - B;
  end;
  ElapsedMs := MilliSecondsBetween(Now, StartTime);
  WriteLn('Branch (pred.):   ', ElapsedMs, ' ms');
end;

procedure BenchmarkBranchUnpredictable;
var i: Integer;
begin
  StartTime := Now;
  for i := 1 to Iterations do
  begin
    if Random(2) = 0 then  // Pattern al√©atoire
      C := A + B
    else
      C := A - B;
  end;
  ElapsedMs := MilliSecondsBetween(Now, StartTime);
  WriteLn('Branch (unpred.): ', ElapsedMs, ' ms');
end;

begin
  Randomize;
  A := 12345;
  B := 67890;

  WriteLn('=== CPU Benchmark ===');
  WriteLn('Iterations: ', Iterations);
  WriteLn;

  BenchmarkAddition;
  BenchmarkMultiplication;
  BenchmarkDivision;
  BenchmarkBitShift;
  BenchmarkBranchPredictable;
  BenchmarkBranchUnpredictable;

  WriteLn;
  WriteLn('Ratios:');
  WriteLn('  Div/Add:  ', (ElapsedDiv / ElapsedAdd):0:1, 'x');
  WriteLn('  Unpred/Pred branch: ', (ElapsedUnpred / ElapsedPred):0:1, 'x');

  ReadLn;
end.

// Exemple de sortie sur Intel i7 :
// === CPU Benchmark ===
// Iterations: 10000000
//
// Addition:         85 ms
// Multiplication:   90 ms
// Division:         2450 ms
// Bit Shift:        82 ms
// Branch (pred.):   180 ms
// Branch (unpred.): 850 ms
//
// Ratios:
//   Div/Add:  28.8x
//   Unpred/Pred branch: 4.7x
```

### Mesurer IPC et efficacit√©

```bash
# Linux avec perf
perf stat -e cycles,instructions,cache-misses,branch-misses ./programme

# Calculer IPC
# IPC = instructions / cycles
```

```pascal
// Inclure les mesures dans le code (Linux)
{$IFDEF LINUX}
uses
  Linux, BaseUnix;

procedure MeasurePerformance;
var
  PerfFD: Integer;
  Counter: Int64;
begin
  // Ouvrir compteur de cycles
  PerfFD := perf_event_open(...);

  // Code √† mesurer
  MyFunction();

  // Lire compteur
  FpRead(PerfFD, Counter, SizeOf(Counter));
  WriteLn('Cycles: ', Counter);
end;
{$ENDIF}
```

## Diff√©rences de performance Windows vs Linux

### Ordonnanceur (Scheduler)

**Windows** :
- Priorit√©s dynamiques
- Pr√©emption par quantum (time slice)
- Affinit√© CPU configurable

**Linux** :
- CFS (Completely Fair Scheduler)
- Meilleure gestion des t√¢ches I/O-bound
- `taskset` pour affinit√© CPU

```bash
# Linux : fixer l'affinit√© CPU
taskset -c 0,1 ./programme  # Ex√©cuter sur cores 0 et 1

# Linux : d√©finir la priorit√©
nice -n -20 ./programme  # Priorit√© maximale
```

```pascal
// Windows : d√©finir l'affinit√©
{$IFDEF WINDOWS}
uses Windows;

procedure SetCPUAffinity(Mask: DWORD_PTR);
begin
  SetThreadAffinityMask(GetCurrentThread, Mask);
end;

// Ex√©cuter sur le core 0 uniquement
SetCPUAffinity(1);  // 0001b = core 0

// Ex√©cuter sur cores 0 et 1
SetCPUAffinity(3);  // 0011b = cores 0,1
{$ENDIF}
```

### Gestion de la m√©moire

**Windows** :
- HeapAlloc/HeapFree
- Virtual Memory Manager
- Large Pages disponibles avec privil√®ges

**Linux** :
- malloc/free (glibc)
- Page Cache tr√®s agressif
- Transparent Huge Pages (THP)

```bash
# Linux : activer THP
echo always > /sys/kernel/mm/transparent_hugepage/enabled

# Linux : flush page cache (test uniquement!)
sync; echo 3 > /proc/sys/vm/drop_caches
```

### Performance relative

| Op√©ration | Windows | Linux | Diff√©rence |
|-----------|---------|-------|------------|
| **Allocation m√©moire** | 100% | 90-110% | Similaire |
| **I/O fichier** | 100% | 130-150% | Linux plus rapide |
| **Cr√©ation thread** | 100% | 120-140% | Linux plus rapide |
| **Appels syst√®me** | 100% | 110-120% | Linux l√©g√®rement plus rapide |
| **Calcul pur** | 100% | 98-102% | Similaire |

**Note** : Ces chiffres sont approximatifs et d√©pendent fortement de la charge de travail.

## Checklist d'optimisation CPU

### Avant d'optimiser

- [ ] Profiler avec perf/VTune pour identifier les hotspots
- [ ] Mesurer IPC (devrait √™tre > 1.5)
- [ ] Mesurer branch miss rate (devrait √™tre < 5%)
- [ ] Mesurer cache miss rate (devrait √™tre < 5%)
- [ ] √âtablir une baseline de performance

### Optimisations √† consid√©rer

**Niveau 1 : Algorithme**
- [ ] Choisir le bon algorithme (O(n log n) vs O(n¬≤))
- [ ] Utiliser les bonnes structures de donn√©es
- [ ] √âliminer les calculs redondants

**Niveau 2 : Pipeline CPU**
- [ ] R√©duire les branchements impr√©visibles
- [ ] √âliminer les fausses d√©pendances
- [ ] R√©organiser le code pour meilleur pipelining

**Niveau 3 : Cache**
- [ ] Am√©liorer la localit√© spatiale (acc√®s s√©quentiels)
- [ ] Am√©liorer la localit√© temporelle (r√©utiliser les donn√©es)
- [ ] Aligner les structures sur les lignes de cache

**Niveau 4 : Instructions**
- [ ] Remplacer divisions par multiplications
- [ ] Utiliser bit shifts pour puissances de 2
- [ ] Utiliser SIMD (voir section 20.3)
- [ ] √âviter les instructions lentes

**Niveau 5 : Compilateur**
- [ ] Compiler avec -O3
- [ ] Sp√©cifier l'architecture cible (-CpCOREAVX2)
- [ ] Activer l'inline de fonctions
- [ ] Tester diff√©rentes options d'optimisation

### Apr√®s optimisation

- [ ] Re-profiler et comparer avec la baseline
- [ ] V√©rifier que IPC a augment√©
- [ ] V√©rifier que cache/branch misses ont diminu√©
- [ ] Valider la correction des r√©sultats
- [ ] Tester sur Windows ET Linux
- [ ] Tester sur diff√©rents CPUs (Intel/AMD/ARM)

## Outils et ressources

### Outils de mesure

**Linux** :
- `perf` : Profilage et compteurs CPU
- `valgrind --tool=cachegrind` : Simulation de cache
- `likwid` : Interface aux compteurs PMU
- `vtune` : Intel VTune (version Linux)

**Windows** :
- Intel VTune Profiler
- AMD uProf
- Windows Performance Analyzer (WPA)

**Multi-plateforme** :
- `google-perftools` : Profiling CPU
- `gperftools` : Alternative √† perf

### Documentation

**Intel** :
- Intel¬Æ 64 and IA-32 Architectures Optimization Reference Manual
- Intel¬Æ Architecture Instruction Set Extensions Programming Reference
- Intel¬Æ Intrinsics Guide

**AMD** :
- Software Optimization Guide for AMD Family Processors
- AMD64 Architecture Programmer's Manual

**ARM** :
- ARM Cortex-A Series Programmer's Guide
- ARM Compiler Optimization Guide

**Livres** :
- "Computer Architecture: A Quantitative Approach" (Hennessy & Patterson)
- "Optimizing Software in C++" (Agner Fog) - Principes applicables √† Pascal
- "What Every Programmer Should Know About Memory" (Ulrich Drepper)

### Sites web et blogs

- Agner Fog's optimization resources : https://www.agner.org/optimize/
- Brendan Gregg's blog : http://www.brendangregg.com/
- Intel Developer Zone : https://software.intel.com/
- LWN.net (Linux performance articles)

## R√©sum√©

### Points cl√©s

‚úÖ **Pipeline CPU** : Comprendre comment le CPU ex√©cute les instructions en parall√®le

‚úÖ **Branch Prediction** : √âcrire du code pr√©visible (< 5% miss rate)

‚úÖ **Cache** : Localit√© spatiale et temporelle cruciales

‚úÖ **IPC** : Viser IPC > 2.0 pour code bien optimis√©

‚úÖ **Instructions** : √âviter division, sqrt, et autres instructions lentes

‚úÖ **SIMD** : Utiliser quand appropri√© (voir section 20.3)

‚úÖ **Multi-plateforme** : Code adaptatif selon CPU/OS

‚úÖ **Mesurer toujours** : Profiler avant et apr√®s optimisation

### Gains typiques par optimisation

| Optimisation | Gain typique |
|--------------|--------------|
| **Meilleur algorithme** | 10x - 1000x |
| **√âliminer branchements** | 1.2x - 3x |
| **Am√©liorer localit√© cache** | 2x - 10x |
| **Loop unrolling** | 1.1x - 1.5x |
| **Remplacer div par mul** | 5x - 30x |
| **SIMD** | 2x - 8x |
| **Alignement m√©moire** | 1.1x - 2x |

### Ordre de priorit√©

1. **Algorithme et structures de donn√©es** (impact maximal)
2. **Localit√© de cache** (souvent le plus important)
3. **Branch prediction** (si beaucoup de branchements)
4. **SIMD et vectorisation** (calcul intensif)
5. **Micro-optimisations** (dernier recours)

### Erreurs √† √©viter

‚ùå Optimiser sans mesurer
‚ùå Micro-optimiser avant l'algorithme
‚ùå Ignorer les diff√©rences de plateformes
‚ùå Sacrifier la lisibilit√© sans gain mesurable
‚ùå Optimiser du code rarement ex√©cut√©

## Conclusion

Les optimisations sp√©cifiques au CPU peuvent transformer un code lent en code rapide, mais elles demandent :
- **Compr√©hension** de l'architecture CPU
- **Mesure** syst√©matique des performances
- **Validation** des r√©sultats sur diff√©rentes plateformes
- **Balance** entre performance et maintenabilit√©

Commencez toujours par les optimisations de haut niveau (algorithme, structures de donn√©es, cache) avant de descendre aux optimisations de bas niveau (instructions sp√©cifiques, assembleur).

Les prochaines sections couvrent :
- **20.5** : Structures de donn√©es optimales
- **20.6** : Algorithmes haute performance
- **20.7** : Memory pools et allocateurs custom

L'optimisation est un processus it√©ratif : mesurer ‚Üí optimiser ‚Üí valider ‚Üí r√©p√©ter !

---

*Note : Ce tutoriel fait partie de la formation "FreePascal/Lazarus - Niveau D√©veloppeur Avanc√© - Edition Multi-plateforme Windows/Ubuntu"*

‚è≠Ô∏è [Structures de donn√©es optimales](/20-optimisation-performance/05-structures-donnees-optimales.md)
