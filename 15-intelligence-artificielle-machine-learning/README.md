🔝 Retour au [Sommaire](/SOMMAIRE.md)

# 15. Intelligence Artificielle et Machine Learning

## Introduction générale

L'Intelligence Artificielle (IA) et le Machine Learning (ML) sont devenus des domaines incontournables du développement logiciel moderne. Bien que ces technologies soient principalement associées à des langages comme Python, FreePascal offre des opportunités uniques pour intégrer des capacités d'IA dans vos applications, particulièrement dans le contexte du développement multi-plateforme Windows/Ubuntu.

### Pourquoi l'IA avec FreePascal ?

Vous vous demandez peut-être : "Pourquoi utiliser FreePascal pour l'IA alors que Python domine ce domaine ?" Voici plusieurs raisons convaincantes :

#### 1. **Performance et efficacité**

FreePascal compile en code machine natif, ce qui offre des performances bien supérieures à Python pour l'exécution :

```
Temps d'exécution typiques (inférence sur 1000 images) :
┌────────────────────┬──────────────┐
│ Python (interprété)│ ~2500 ms     │
│ Python + NumPy     │ ~800 ms      │
│ FreePascal natif   │ ~300 ms      │
│ FreePascal + SIMD  │ ~150 ms      │
└────────────────────┴──────────────┘
```

#### 2. **Déploiement simplifié**

- **Exécutables autonomes** : Pas besoin d'installer Python et ses dépendances
- **Taille réduite** : Applications de quelques Mo au lieu de centaines
- **Compatibilité** : Fonctionne sur des systèmes sans environnement Python

#### 3. **Intégration native dans vos applications**

Si vous développez déjà des applications Lazarus, intégrer l'IA devient naturel :

```pascal
// Dans votre application Lazarus existante
procedure TMainForm.ButtonRecognizeClick(Sender: TObject);
var
  prediction: string;
begin
  prediction := MyNeuralNetwork.Predict(ImageToAnalyze);
  LabelResult.Caption := 'Résultat : ' + prediction;
end;
```

#### 4. **Contrôle total et typage fort**

- **Sécurité** : Le typage strict de Pascal évite de nombreuses erreurs
- **Débogage** : Outils de débogage natifs plus efficaces
- **Optimisation** : Contrôle précis de la mémoire et des performances

#### 5. **Multi-plateforme cohérent**

Le même code fonctionne sur Windows et Ubuntu sans adaptation :

```pascal
{$IFDEF WINDOWS}
  // Utilise les mêmes algorithmes
{$ENDIF}
{$IFDEF LINUX}
  // Avec les mêmes résultats
{$ENDIF}
```

## Qu'est-ce que l'Intelligence Artificielle et le Machine Learning ?

### Intelligence Artificielle (IA)

L'**Intelligence Artificielle** est un domaine de l'informatique qui vise à créer des systèmes capables de réaliser des tâches qui nécessitent normalement l'intelligence humaine :

- Reconnaissance d'images et de visages
- Compréhension du langage naturel
- Prise de décision dans des environnements complexes
- Jeux stratégiques (échecs, Go)
- Conduite autonome
- Diagnostic médical

### Machine Learning (Apprentissage Automatique)

Le **Machine Learning** est une sous-catégorie de l'IA où les systèmes apprennent à partir de données sans être explicitement programmés pour chaque cas :

```
Programmation classique :
Données + Programme → Résultats

Machine Learning :
Données + Résultats souhaités → Programme (modèle)
```

#### Exemple concret

**Programmation classique** (détection de spam) :
```pascal
function IsSpam(email: string): Boolean;
begin
  Result := (Pos('viagra', LowerCase(email)) > 0) or
            (Pos('casino', LowerCase(email)) > 0) or
            (Pos('winner', LowerCase(email)) > 0);
  // Liste interminable de règles...
end;
```

**Machine Learning** (détection de spam) :
```pascal
// Le modèle apprend automatiquement les patterns
function IsSpam(email: string): Boolean;
begin
  Result := TrainedModel.Predict(email) > 0.5;
  // Le modèle a appris sur des milliers d'exemples
end;
```

### Les trois types d'apprentissage

#### 1. Apprentissage supervisé

Le système apprend à partir d'exemples étiquetés :

```
Exemples d'entraînement :
Image de chat → "chat"
Image de chien → "chien"
Image de chat → "chat"
...

Après apprentissage :
Nouvelle image → Prédiction : "chat" ou "chien"
```

**Applications :**
- Classification d'images
- Détection de fraude
- Prédiction de prix
- Reconnaissance vocale

#### 2. Apprentissage non supervisé

Le système découvre des structures dans des données non étiquetées :

```
Données clients (sans catégories) →
Algorithme de clustering →
Groupes découverts :
  - Jeunes urbains
  - Familles rurales
  - Seniors actifs
```

**Applications :**
- Segmentation de clientèle
- Détection d'anomalies
- Compression de données
- Systèmes de recommandation

#### 3. Apprentissage par renforcement

Le système apprend en interagissant avec un environnement :

```
Agent → Action → Environnement
   ↑                    ↓
   └── Récompense ←─────┘

Exemple : Jeu vidéo
Action : Sauter
Récompense : +10 (a évité un obstacle)
          ou -10 (est tombé dans un trou)
```

**Applications :**
- Jeux (AlphaGo)
- Robotique
- Gestion de ressources
- Trading automatisé

## Concepts fondamentaux du Machine Learning

### 1. Les données d'entraînement

Les données sont le carburant du Machine Learning. Un modèle est aussi bon que les données sur lesquelles il a été entraîné.

```pascal
type
  TTrainingExample = record
    Input: array of Double;   // Les caractéristiques (features)
    Output: Double;            // Le résultat attendu (label)
  end;

var
  TrainingSet: array of TTrainingExample;
```

**Exemple : Prédire le prix d'une maison**

```pascal
// Input = [Surface, Nombre de chambres, Année de construction]
// Output = Prix

TrainingSet[0].Input := [120.0, 3.0, 2010.0];
TrainingSet[0].Output := 250000.0;

TrainingSet[1].Input := [85.0, 2.0, 1995.0];
TrainingSet[1].Output := 180000.0;
// ... des milliers d'exemples
```

### 2. Les caractéristiques (Features)

Les **features** sont les attributs mesurables des données d'entrée :

```
Image (28x28 pixels) → 784 features (valeurs de pixels)
Email → [longueur, nb_majuscules, présence_URL, ...] → Features
Signal audio → [fréquences, amplitude, ...] → Features
```

**Ingénierie des caractéristiques** : L'art de transformer les données brutes en features pertinentes.

### 3. Le modèle

Le **modèle** est la représentation mathématique qui fait le lien entre les entrées et les sorties :

```pascal
type
  TModel = class
  private
    Weights: array of Double;  // Paramètres du modèle
    Bias: Double;
  public
    function Predict(Input: array of Double): Double;
    procedure Train(TrainingData: TTrainingSet);
  end;
```

### 4. L'entraînement

L'**entraînement** est le processus d'ajustement des paramètres du modèle pour minimiser l'erreur :

```
1. Initialiser le modèle avec des poids aléatoires
2. Pour chaque exemple d'entraînement :
   a. Faire une prédiction
   b. Calculer l'erreur
   c. Ajuster les poids pour réduire l'erreur
3. Répéter jusqu'à convergence
```

**Visualisation du processus :**

```
Erreur
  ↑
  │     ●  ← Début (erreur élevée)
  │    / \
  │   /   \
  │  /     \    ● ← Après quelques itérations
  │ /       \  /
  │/         \/  ← Minimum (meilleur modèle)
  └─────────────────→ Itérations
```

### 5. La fonction de perte (Loss Function)

La **fonction de perte** mesure à quel point les prédictions du modèle sont éloignées des vraies valeurs :

```pascal
function MeanSquaredError(Predictions, Targets: array of Double): Double;
var
  i: Integer;
  Sum: Double;
begin
  Sum := 0;
  for i := 0 to High(Predictions) do
    Sum := Sum + Sqr(Predictions[i] - Targets[i]);
  Result := Sum / Length(Predictions);
end;
```

### 6. L'optimisation

L'**optimisateur** ajuste les paramètres pour minimiser la fonction de perte. L'algorithme le plus courant est la **descente de gradient** :

```pascal
// Principe simplifié
procedure UpdateWeight(var Weight: Double; Gradient, LearningRate: Double);
begin
  Weight := Weight - LearningRate * Gradient;
end;
```

Le **taux d'apprentissage** (learning rate) contrôle la vitesse d'apprentissage :

```
Trop petit → Apprentissage très lent
Trop grand → Le modèle ne converge pas
```

### 7. La validation et le test

Pour éviter le **surapprentissage** (overfitting), on divise les données :

```
Données totales (100%)
├── Entraînement (70%) → Pour apprendre
├── Validation (15%)   → Pour ajuster les hyperparamètres
└── Test (15%)         → Pour évaluer la performance finale
```

```pascal
type
  TDataSplit = record
    Training: TDataSet;   // 70%
    Validation: TDataSet; // 15%
    Test: TDataSet;       // 15%
  end;

function SplitData(AllData: TDataSet): TDataSplit;
begin
  // Mélanger aléatoirement
  // Diviser selon les proportions
end;
```

## Les réseaux de neurones

Les **réseaux de neurones** s'inspirent du cerveau humain et sont au cœur du Deep Learning moderne.

### Le neurone artificiel

Un neurone artificiel est une unité de calcul simple :

```
         Entrées
           ↓
    [x₁] ──→ w₁ ↘
    [x₂] ──→ w₂ ─→ Σ → f(.) → Sortie
    [x₃] ──→ w₃ ↗
           + bias
```

**En Pascal :**

```pascal
type
  TNeuron = class
  private
    Weights: array of Double;
    Bias: Double;
    function ActivationFunction(x: Double): Double;
  public
    function ComputeOutput(Inputs: array of Double): Double;
  end;

function TNeuron.ComputeOutput(Inputs: array of Double): Double;
var
  i: Integer;
  Sum: Double;
begin
  Sum := Bias;
  for i := 0 to High(Inputs) do
    Sum := Sum + Inputs[i] * Weights[i];
  Result := ActivationFunction(Sum);
end;
```

### Fonctions d'activation

Les **fonctions d'activation** introduisent de la non-linéarité :

```pascal
// Sigmoid : Sortie entre 0 et 1
function Sigmoid(x: Double): Double;
begin
  Result := 1.0 / (1.0 + Exp(-x));
end;

// ReLU : Max(0, x) - Très populaire
function ReLU(x: Double): Double;
begin
  if x > 0 then
    Result := x
  else
    Result := 0;
end;

// Tanh : Sortie entre -1 et 1
function Tanh(x: Double): Double;
begin
  Result := (Exp(x) - Exp(-x)) / (Exp(x) + Exp(-x));
end;
```

### Architecture d'un réseau

Un réseau de neurones est organisé en **couches** :

```
Entrée → [Couche cachée 1] → [Couche cachée 2] → Sortie

Exemple : Reconnaissance de chiffres manuscrits
[784 neurones] → [128] → [64] → [10 neurones]
   (28×28)        cachée  cachée  (0-9)
```

```pascal
type
  TNeuralNetwork = class
  private
    Layers: array of TLayer;
  public
    constructor Create(LayerSizes: array of Integer);
    function Forward(Input: TVector): TVector;
    procedure Backpropagate(Error: TVector);
    procedure Train(TrainingData: TDataSet; Epochs: Integer);
  end;
```

## Domaines d'application en FreePascal

### 1. Vision par ordinateur

**Applications :**
- Reconnaissance faciale
- Détection d'objets
- Classification d'images
- OCR (reconnaissance de caractères)

**Exemple de cas d'usage :**
```pascal
// Application de tri automatique de documents
function ClassifyDocument(ImagePath: string): TDocumentType;
var
  CNN: TConvolutionalNetwork;
begin
  CNN := TConvolutionalNetwork.LoadFromFile('model.dat');
  Result := CNN.PredictDocumentType(ImagePath);
  // Retourne : Invoice, Contract, Letter, etc.
end;
```

### 2. Traitement du langage naturel (NLP)

**Applications :**
- Analyse de sentiment
- Traduction automatique
- Chatbots
- Classification de textes

**Exemple :**
```pascal
// Détection de langue
function DetectLanguage(Text: string): string;
var
  Model: TLanguageClassifier;
begin
  Model := TLanguageClassifier.Create;
  Result := Model.Predict(Text);
  // Retourne : 'fr', 'en', 'es', etc.
end;
```

### 3. Systèmes de recommandation

**Applications :**
- Recommandations e-commerce
- Suggestions de contenu
- Personnalisation

### 4. Détection d'anomalies

**Applications :**
- Détection de fraude
- Monitoring de systèmes
- Contrôle qualité industriel

**Exemple :**
```pascal
// Surveillance de serveur
function IsAnomalous(Metrics: TServerMetrics): Boolean;
var
  Detector: TAnomalyDetector;
  AnomalyScore: Double;
begin
  Detector := TAnomalyDetector.LoadModel('server_model.dat');
  AnomalyScore := Detector.ComputeScore(Metrics);
  Result := AnomalyScore > THRESHOLD;
end;
```

### 5. Prédiction de séries temporelles

**Applications :**
- Prévisions de ventes
- Prédictions boursières
- Prévisions météo
- Maintenance prédictive

### 6. Jeux et agents intelligents

**Applications :**
- Adversaires IA dans les jeux
- Bots pour jeux de stratégie
- Optimisation de gameplay

## L'écosystème IA pour FreePascal

### Outils et bibliothèques disponibles

#### 1. **Bibliothèques natives Pascal**

Développer vos propres algorithmes :
- Contrôle total du code
- Optimisations spécifiques
- Pas de dépendances externes

#### 2. **Bindings vers bibliothèques C/C++**

Utiliser des bibliothèques établies :
- **TensorFlow** (via bindings C)
- **OpenCV** (vision par ordinateur)
- **ONNX Runtime** (modèles portables)

#### 3. **Intégration Python**

Combiner le meilleur des deux mondes :
- **Python4Lazarus** : Exécuter du code Python depuis Pascal
- Entraîner en Python, déployer en Pascal

```pascal
uses
  PythonEngine;

procedure TrainModelInPython;
begin
  PythonEngine.ExecString('import tensorflow as tf');
  PythonEngine.ExecString('model = tf.keras.models.Sequential([...])');
  PythonEngine.ExecString('model.fit(X_train, y_train)');
  PythonEngine.ExecString('model.save("model.h5")');
end;
```

#### 4. **Formats de modèles standards**

- **ONNX** : Échange de modèles entre frameworks
- **PMML** : Modèles de ML classiques
- **JSON/Custom** : Sérialisation de vos propres modèles

### Outils de développement

#### 1. **Pour l'entraînement**

Même si vous déployez en Pascal, vous pouvez entraîner avec :
- **Python/Jupyter** : Expérimentation rapide
- **TensorFlow/PyTorch** : Frameworks puissants
- **AutoML** : Entraînement automatisé

#### 2. **Pour le déploiement**

- **FreePascal** : Application finale performante
- **Lazarus** : Interface utilisateur riche
- **Cross-compilation** : Windows et Ubuntu

#### 3. **Pour l'optimisation**

- **Profiling** : Identifier les goulots d'étranglement
- **SIMD** : Vectorisation pour performances
- **Multi-threading** : Parallélisation

## Workflow typique IA avec FreePascal

### Phase 1 : Collecte et préparation des données

```pascal
// Charger et nettoyer les données
var
  RawData: TDataSet;
  CleanData: TDataSet;
begin
  RawData := LoadFromCSV('data.csv');
  CleanData := PreprocessData(RawData);
  NormalizeData(CleanData);
  SaveProcessedData(CleanData, 'processed.dat');
end;
```

### Phase 2 : Entraînement (Python ou Pascal)

**Option A : Entraînement en Python**
```python
# train_model.py
import numpy as np
from sklearn.ensemble import RandomForestClassifier

# Charger les données
X, y = load_data('processed.dat')

# Entraîner
model = RandomForestClassifier()
model.fit(X, y)

# Exporter pour Pascal
export_model_weights(model, 'model.bin')
```

**Option B : Entraînement en Pascal**
```pascal
var
  Model: TNeuralNetwork;
  TrainingData: TDataSet;
begin
  Model := TNeuralNetwork.Create([784, 128, 64, 10]);
  TrainingData := LoadTrainingData('processed.dat');
  Model.Train(TrainingData, Epochs := 100);
  Model.SaveToFile('model.dat');
end;
```

### Phase 3 : Intégration dans l'application

```pascal
// Dans votre application Lazarus
type
  TMainForm = class(TForm)
  private
    AIModel: TNeuralNetwork;
  public
    procedure LoadModel;
    procedure MakePrediction(Input: TData);
  end;

procedure TMainForm.FormCreate(Sender: TObject);
begin
  AIModel := TNeuralNetwork.LoadFromFile('model.dat');
end;

procedure TMainForm.ButtonPredictClick(Sender: TObject);
var
  Input: TVector;
  Result: string;
begin
  Input := PrepareInputData(EditData.Text);
  Result := AIModel.PredictClass(Input);
  LabelResult.Caption := 'Prédiction : ' + Result;
end;
```

### Phase 4 : Déploiement multi-plateforme

```bash
# Compilation Windows
lazbuild --os=win64 --cpu=x86_64 myapp.lpi

# Compilation Ubuntu
lazbuild --os=linux --cpu=x86_64 myapp.lpi

# Résultat : Une application autonome avec IA intégrée
```

## Mathématiques pour le Machine Learning

### Niveau requis

Pas de panique ! Vous n'avez pas besoin d'un doctorat en mathématiques. Voici les bases :

#### 1. **Algèbre linéaire** (essentiel)

- Vecteurs et matrices
- Multiplication matricielle
- Produit scalaire

```pascal
// Produit scalaire de deux vecteurs
function DotProduct(A, B: array of Double): Double;
var
  i: Integer;
begin
  Result := 0;
  for i := 0 to High(A) do
    Result := Result + A[i] * B[i];
end;
```

#### 2. **Calcul différentiel** (pour comprendre l'optimisation)

- Dérivées
- Gradient
- Descente de gradient

```pascal
// Dérivée de f(x) = x² en x
function Derivative_x_squared(x: Double): Double;
begin
  Result := 2 * x;
end;
```

#### 3. **Probabilités et statistiques** (utile)

- Moyenne, variance
- Distributions
- Probabilités conditionnelles

```pascal
function Mean(Data: array of Double): Double;
var
  Sum: Double;
  i: Integer;
begin
  Sum := 0;
  for i := 0 to High(Data) do
    Sum := Sum + Data[i];
  Result := Sum / Length(Data);
end;
```

### Bibliothèques mathématiques pour FreePascal

- **Math unit** : Fonctions de base (Exp, Log, Sqrt, etc.)
- **NumLib** : Calcul numérique avancé
- **Custom matrices** : Créer vos propres structures

```pascal
uses
  Math; // Fonctions mathématiques de base

var
  x: Double;
begin
  x := Power(2, 10);    // 2^10
  x := Exp(1);          // e^1
  x := Ln(10);          // log naturel
  x := ArcTan(1);       // arctan
end;
```

## Performance et optimisation

### Techniques d'optimisation en Pascal

#### 1. **Types de données appropriés**

```pascal
// Lent : utiliser Extended quand Single suffit
var
  Weights: array of Extended;  // 80 bits

// Rapide : utiliser Single pour les NN
var
  Weights: array of Single;    // 32 bits (4x plus compact)
```

#### 2. **Allocation mémoire efficace**

```pascal
// Lent : réallocations multiples
procedure SlowWay;
var
  Data: array of Double;
  i: Integer;
begin
  for i := 0 to 9999 do
  begin
    SetLength(Data, i + 1);  // Réallocation à chaque fois !
    Data[i] := i;
  end;
end;

// Rapide : préallocation
procedure FastWay;
var
  Data: array of Double;
  i: Integer;
begin
  SetLength(Data, 10000);  // Une seule allocation
  for i := 0 to 9999 do
    Data[i] := i;
end;
```

#### 3. **Inline pour les fonctions critiques**

```pascal
// Fonction appelée des millions de fois
function ReLU(x: Double): Double; inline;
begin
  if x > 0 then
    Result := x
  else
    Result := 0;
end;
```

#### 4. **SIMD et vectorisation**

Utiliser les instructions SIMD du processeur pour traiter plusieurs données simultanément :

```pascal
// Standard : traiter 1 donnée à la fois
// SIMD : traiter 4 ou 8 données simultanément (AVX)
```

## Défis et considérations

### Défis techniques

1. **Bibliothèques limitées** : Moins d'outils prêts à l'emploi qu'en Python
2. **Communauté plus petite** : Moins de ressources et tutoriels
3. **Debugging** : Les modèles IA sont complexes à déboguer
4. **GPU** : Support CUDA/OpenCL moins mature

### Solutions et bonnes pratiques

1. **Commencer simple** : Algorithmes classiques avant Deep Learning
2. **Utiliser des bindings** : TensorFlow C API, ONNX Runtime
3. **Combiner avec Python** : Entraîner en Python, déployer en Pascal
4. **Tester rigoureusement** : Valider chaque composant

## Contenu des prochains chapitres

Ce chapitre 15 va couvrir :

- **15.1** Bindings TensorFlow pour FreePascal
- **15.2** Réseaux de neurones from scratch (implémentation complète)
- **15.3** Computer Vision avec OpenCV
- **15.4** NLP et traitement de texte
- **15.5** Algorithmes génétiques
- **15.6** Apprentissage par renforcement
- **15.7** Intégration avec Python (Python4Lazarus)
- **15.8** ONNX et modèles portables
- **15.9** GPU computing avec CUDA/OpenCL
- **15.10** Déploiement de modèles IA

## Ressources pour débuter

### Livres et cours (généraux sur l'IA)

- "Introduction to Machine Learning" - comprendre les concepts
- "Deep Learning" de Ian Goodfellow - référence technique
- Cours en ligne Coursera, edX - fondamentaux

### Ressources FreePascal

- Forums FreePascal - section algorithmes
- GitHub - rechercher "pascal neural network"
- Wiki FreePascal - bindings et bibliothèques externes

### Projets open source à étudier

- Implémentations de réseaux de neurones en Pascal
- Computer Vision projects
- Algorithmes génétiques

## Conclusion

L'Intelligence Artificielle et le Machine Learning avec FreePascal représentent une opportunité unique de combiner :

✅ **Performance** du code natif compilé
✅ **Portabilité** multi-plateforme (Windows/Ubuntu)
✅ **Intégration** naturelle dans vos applications existantes
✅ **Contrôle** total sur le code et les optimisations

Bien que l'écosystème soit moins mature qu'en Python, FreePascal offre des avantages significatifs pour le **déploiement en production** d'applications IA, particulièrement dans les contextes où la performance, la fiabilité et l'autonomie sont critiques.

Les chapitres suivants vous guideront à travers l'implémentation concrète de solutions IA, des concepts les plus simples (régression linéaire) aux plus avancés (réseaux de neurones profonds), toujours avec une approche pratique et accessible, même pour ceux qui découvrent le domaine.

---

**Prérequis recommandés avant de continuer :**
- Maîtrise de l'Object Pascal (chapitre 3)
- Compréhension des algorithmes et structures de données
- Bases en mathématiques (algèbre, calcul)
- Patience et curiosité ! Le Machine Learning est un voyage d'apprentissage continu.

**Prêt à commencer ?** Direction le chapitre 15.1 sur les bindings TensorFlow !

⏭️ [Bindings TensorFlow pour FreePascal](/15-intelligence-artificielle-machine-learning/01-bindings-tensorflow-freepascal.md)
