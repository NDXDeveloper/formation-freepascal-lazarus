üîù Retour au [Sommaire](/SOMMAIRE.md)

# 16.8 Calcul parall√®le et vectorisation

## Introduction

Le calcul parall√®le et la vectorisation sont deux techniques compl√©mentaires qui permettent d'exploiter pleinement la puissance des processeurs modernes. Dans ce chapitre, nous allons d√©couvrir comment FreePascal permet d'acc√©l√©rer consid√©rablement vos calculs scientifiques et de traitement de donn√©es.

### Pourquoi c'est important ?

Les processeurs modernes poss√®dent :
- **Plusieurs c≈ìurs** (g√©n√©ralement 4 √† 16 sur les ordinateurs de bureau)
- **Des instructions SIMD** (Single Instruction Multiple Data) qui permettent de traiter plusieurs donn√©es en une seule op√©ration

Sans optimisation, votre code n'utilise qu'un seul c≈ìur et traite les donn√©es une par une. Avec le calcul parall√®le et la vectorisation, vous pouvez multiplier les performances par 10, 20, voire plus !

---

## Partie 1 : Le calcul parall√®le

### 1.1 Comprendre le parall√©lisme

Le calcul parall√®le consiste √† diviser un travail en plusieurs t√¢ches qui s'ex√©cutent simultan√©ment sur diff√©rents c≈ìurs du processeur.

**Analogie simple :** Imaginez que vous devez plier 1000 feuilles de papier. Si vous √™tes seul, cela prend du temps. Mais si 4 personnes travaillent ensemble, chacune pliant 250 feuilles, le travail est termin√© 4 fois plus vite !

### 1.2 Les threads en FreePascal

FreePascal utilise la classe `TThread` pour cr√©er des threads (fils d'ex√©cution parall√®les).

#### Exemple simple : Calcul parall√®le d'une somme

```pascal
uses
  Classes, SysUtils;

type
  // Thread qui calcule la somme d'une partie du tableau
  TSumThread = class(TThread)
  private
    FData: array of Double;
    FStart, FEnd: Integer;
    FResult: Double;
  protected
    procedure Execute; override;
  public
    constructor Create(const Data: array of Double; AStart, AEnd: Integer);
    property Result: Double read FResult;
  end;

constructor TSumThread.Create(const Data: array of Double; AStart, AEnd: Integer);
var
  i: Integer;
begin
  inherited Create(True); // Cr√©√© en pause
  FreeOnTerminate := False;
  FStart := AStart;
  FEnd := AEnd;

  // Copie des donn√©es
  SetLength(FData, Length(Data));
  for i := 0 to High(Data) do
    FData[i] := Data[i];
end;

procedure TSumThread.Execute;
var
  i: Integer;
begin
  FResult := 0;
  for i := FStart to FEnd do
    FResult := FResult + FData[i];
end;

// Fonction qui utilise plusieurs threads
function ParallelSum(const Data: array of Double; NumThreads: Integer): Double;
var
  Threads: array of TSumThread;
  ChunkSize, i, Start, Finish: Integer;
begin
  Result := 0;
  SetLength(Threads, NumThreads);
  ChunkSize := Length(Data) div NumThreads;

  // Cr√©ation et d√©marrage des threads
  for i := 0 to NumThreads - 1 do
  begin
    Start := i * ChunkSize;
    if i = NumThreads - 1 then
      Finish := High(Data)
    else
      Finish := Start + ChunkSize - 1;

    Threads[i] := TSumThread.Create(Data, Start, Finish);
    Threads[i].Start;
  end;

  // Attente de la fin et r√©cup√©ration des r√©sultats
  for i := 0 to NumThreads - 1 do
  begin
    Threads[i].WaitFor;
    Result := Result + Threads[i].Result;
    Threads[i].Free;
  end;
end;
```

### 1.3 La biblioth√®que MTProcs

FreePascal inclut la biblioth√®que **MTProcs** (Multi-Threading Procedures) qui simplifie grandement le calcul parall√®le.

#### Installation et utilisation

```pascal
uses
  MTProcs;

// Exemple : Traitement parall√®le d'un tableau
procedure ProcessArrayParallel(var Data: array of Double);
var
  i: Integer;
begin
  ProcThreadPool.DoParallel(
    @ProcessElement,  // Fonction √† appeler
    0,                // Index de d√©but
    High(Data),       // Index de fin
    @Data             // Donn√©es
  );
end;

// Fonction appliqu√©e √† chaque √©l√©ment
procedure ProcessElement(Index: PtrInt; Data: Pointer; Item: TMultiThreadProcItem);
var
  Arr: ^array of Double;
begin
  Arr := Data;
  Arr^[Index] := Sqrt(Arr^[Index]) * 2.5;
end;
```

### 1.4 Parall√©lisation d'une boucle FOR

MTProcs offre une fonction tr√®s pratique pour parall√©liser automatiquement une boucle :

```pascal
uses
  MTProcs;

var
  Data: array of Double;
  i: Integer;

begin
  SetLength(Data, 1000000);

  // Remplissage des donn√©es
  for i := 0 to High(Data) do
    Data[i] := Random * 100;

  // Traitement parall√®le
  ProcThreadPool.DoParallelLocalProc(
    procedure(Index: PtrInt; ThreadIndex: PtrInt; Data: Pointer)
    begin
      // Cette proc√©dure s'ex√©cute en parall√®le pour chaque index
      TDoubleArray(Data)[Index] := Sqrt(TDoubleArray(Data)[Index]);
    end,
    0, High(Data), @Data
  );
end;
```

### 1.5 Points d'attention

‚ö†Ô∏è **Probl√®mes courants √† √©viter :**

1. **Race conditions** : Plusieurs threads modifient la m√™me variable
   ```pascal
   // MAUVAIS - race condition !
   var GlobalSum: Double = 0;

   // Plusieurs threads font :
   GlobalSum := GlobalSum + LocalValue;  // DANGER !
   ```

2. **Solution** : Utiliser des sections critiques ou des variables locales
   ```pascal
   uses
     SyncObjs;

   var
     CriticalSection: TCriticalSection;
     GlobalSum: Double = 0;

   // Dans le thread :
   CriticalSection.Enter;
   try
     GlobalSum := GlobalSum + LocalValue;  // Prot√©g√©
   finally
     CriticalSection.Leave;
   end;
   ```

---

## Partie 2 : La vectorisation (SIMD)

### 2.1 Qu'est-ce que SIMD ?

SIMD (Single Instruction Multiple Data) permet d'appliquer une m√™me op√©ration sur plusieurs donn√©es simultan√©ment.

**Exemple concret :** Au lieu d'additionner 4 paires de nombres en 4 op√©rations :
```
a1 + b1 = c1
a2 + b2 = c2
a3 + b3 = c3
a4 + b4 = c4
```

Une instruction SIMD fait les 4 additions EN UNE SEULE OP√âRATION !

### 2.2 Les jeux d'instructions SIMD

Les processeurs modernes supportent plusieurs g√©n√©rations de SIMD :

| Jeu d'instructions | Largeur | Support |
|-------------------|---------|---------|
| SSE | 128 bits | Tous les x86-64 |
| SSE2, SSE3, SSE4 | 128 bits | Tr√®s r√©pandu |
| AVX | 256 bits | Processeurs r√©cents (2011+) |
| AVX2 | 256 bits | Processeurs r√©cents (2013+) |
| AVX-512 | 512 bits | Serveurs et tr√®s haut de gamme |

### 2.3 Vectorisation automatique par le compilateur

FreePascal peut vectoriser automatiquement certaines boucles si vous activez les bonnes options de compilation.

#### Options de compilation recommand√©es

```bash
# Compilation avec optimisations maximales
fpc -O3 -CpCOREAVX2 -FaAVX2 monprogramme.pas
```

**Explications :**
- `-O3` : Niveau d'optimisation maximum
- `-CpCOREAVX2` : G√©n√®re du code pour les processeurs supportant AVX2
- `-FaAVX2` : Active explicitement les instructions AVX2

#### Exemple de code vectorisable

```pascal
procedure AddArrays(const A, B: array of Single; var C: array of Single);
var
  i: Integer;
begin
  // Cette boucle simple peut √™tre vectoris√©e automatiquement
  for i := 0 to High(A) do
    C[i] := A[i] + B[i];
end;
```

Le compilateur avec `-O3` transformera cette boucle pour utiliser des instructions SIMD qui additionnent 4, 8 ou 16 valeurs √† la fois !

### 2.4 Vectorisation manuelle avec inline assembler

Pour un contr√¥le total, vous pouvez √©crire du code SIMD directement en assembleur inline.

#### Exemple SSE : Addition de 4 floats

```pascal
procedure AddVectorsSSE(const A, B: array of Single; var Result: array of Single; Count: Integer);
var
  i: Integer;
begin
  i := 0;

  // Traitement par paquets de 4
  while i <= Count - 4 do
  begin
    asm
      mov eax, A
      mov ebx, B
      mov ecx, Result
      mov edx, i

      // Charger 4 floats de A
      movups xmm0, [eax + edx*4]

      // Charger 4 floats de B
      movups xmm1, [ebx + edx*4]

      // Addition vectorielle
      addps xmm0, xmm1

      // Sauvegarder le r√©sultat
      movups [ecx + edx*4], xmm0
    end;

    Inc(i, 4);
  end;

  // Traiter les √©l√©ments restants
  while i < Count do
  begin
    Result[i] := A[i] + B[i];
    Inc(i);
  end;
end;
```

#### Exemple AVX : Addition de 8 floats

```pascal
procedure AddVectorsAVX(const A, B: array of Single; var Result: array of Single; Count: Integer);
var
  i: Integer;
begin
  i := 0;

  // Traitement par paquets de 8
  while i <= Count - 8 do
  begin
    asm
      mov rax, A
      mov rbx, B
      mov rcx, Result
      mov rdx, i

      // Charger 8 floats de A (256 bits)
      vmovups ymm0, [rax + rdx*4]

      // Charger 8 floats de B
      vmovups ymm1, [rbx + rdx*4]

      // Addition vectorielle de 8 floats simultan√©ment
      vaddps ymm0, ymm0, ymm1

      // Sauvegarder le r√©sultat
      vmovups [rcx + rdx*4], ymm0
    end;

    Inc(i, 8);
  end;

  // Traiter les √©l√©ments restants
  while i < Count do
  begin
    Result[i] := A[i] + B[i];
    Inc(i);
  end;
end;
```

### 2.5 D√©tection des capacit√©s du processeur

Avant d'utiliser des instructions SIMD avanc√©es, v√©rifiez que le processeur les supporte :

```pascal
uses
  CPU;  // Unit incluse dans FreePascal

function GetCPUFeatures: string;
begin
  Result := '';

  if SSESupport then
    Result := Result + 'SSE ';
  if SSE2Support then
    Result := Result + 'SSE2 ';
  if SSE3Support then
    Result := Result + 'SSE3 ';
  if SSSE3Support then
    Result := Result + 'SSSE3 ';
  if SSE41Support then
    Result := Result + 'SSE4.1 ';
  if SSE42Support then
    Result := Result + 'SSE4.2 ';
  if AVXSupport then
    Result := Result + 'AVX ';
  if AVX2Support then
    Result := Result + 'AVX2 ';
end;

// Utilisation adaptative
procedure AddVectorsAdaptive(const A, B: array of Single; var Result: array of Single);
begin
  if AVX2Support then
    AddVectorsAVX(A, B, Result, Length(A))
  else if SSESupport then
    AddVectorsSSE(A, B, Result, Length(A))
  else
    AddVectorsScalar(A, B, Result, Length(A));
end;
```

---

## Partie 3 : Combiner parall√©lisme et vectorisation

### 3.1 La puissance de la combinaison

Pour des performances optimales, combinez calcul parall√®le ET vectorisation :

```pascal
uses
  MTProcs;

procedure OptimizedMatrixMultiply(const A, B: TMatrix; var C: TMatrix);
begin
  // Parall√©lisation sur les lignes
  ProcThreadPool.DoParallelLocalProc(
    procedure(RowIndex: PtrInt; ThreadIndex: PtrInt; Data: Pointer)
    var
      Col, K: Integer;
      Sum: Single;
    begin
      // Pour chaque colonne
      for Col := 0 to High(B[0]) do
      begin
        Sum := 0;

        // Produit scalaire vectoris√© (le compilateur optimise cette boucle)
        for K := 0 to High(A[0]) do
          Sum := Sum + A[RowIndex][K] * B[K][Col];

        C[RowIndex][Col] := Sum;
      end;
    end,
    0, High(A), nil
  );
end;
```

### 3.2 Exemple complet : Traitement d'image

Voici un exemple complet qui combine tout ce que nous avons vu :

```pascal
program OptimizedImageProcessing;

uses
  Classes, SysUtils, MTProcs;

type
  TPixel = packed record
    B, G, R, A: Byte;
  end;

  TImageData = array of array of TPixel;

// Applique un flou gaussien en parall√®le et vectoris√©
procedure ApplyBlurParallel(var Image: TImageData; Radius: Integer);
var
  Height, Width: Integer;
begin
  Height := Length(Image);
  Width := Length(Image[0]);

  // Traitement parall√®le de chaque ligne
  ProcThreadPool.DoParallelLocalProc(
    procedure(Row: PtrInt; ThreadIndex: PtrInt; Data: Pointer)
    var
      Col, dy, dx: Integer;
      SumR, SumG, SumB, Count: Integer;
    begin
      // Pour chaque pixel de la ligne
      for Col := 0 to Width - 1 do
      begin
        SumR := 0; SumG := 0; SumB := 0; Count := 0;

        // Calcul de la moyenne dans le rayon
        // (Cette boucle peut √™tre vectoris√©e par le compilateur)
        for dy := -Radius to Radius do
        begin
          if (Row + dy >= 0) and (Row + dy < Height) then
          begin
            for dx := -Radius to Radius do
            begin
              if (Col + dx >= 0) and (Col + dx < Width) then
              begin
                Inc(SumR, Image[Row + dy][Col + dx].R);
                Inc(SumG, Image[Row + dy][Col + dx].G);
                Inc(SumB, Image[Row + dy][Col + dx].B);
                Inc(Count);
              end;
            end;
          end;
        end;

        // Application du r√©sultat
        Image[Row][Col].R := SumR div Count;
        Image[Row][Col].G := SumG div Count;
        Image[Row][Col].B := SumB div Count;
      end;
    end,
    0, Height - 1, nil
  );
end;

begin
  WriteLn('Traitement d''image optimis√© avec parall√©lisme et vectorisation');
end.
```

---

## Partie 4 : Bonnes pratiques et optimisation

### 4.1 Quand utiliser le parall√©lisme ?

‚úÖ **OUI, parall√©lisez quand :**
- Les calculs sont longs (>10ms par t√¢che)
- Les t√¢ches sont ind√©pendantes
- Vous traitez de grandes quantit√©s de donn√©es

‚ùå **NON, √©vitez quand :**
- Les calculs sont tr√®s rapides (<1ms)
- Les t√¢ches d√©pendent fortement les unes des autres
- Vous avez peu de donn√©es (overhead du parall√©lisme)

### 4.2 Mesurer les performances

Toujours mesurer avant et apr√®s optimisation :

```pascal
uses
  SysUtils;

var
  StartTime, EndTime: TDateTime;
  ElapsedMs: Int64;

begin
  StartTime := Now;

  // Votre code √† mesurer
  ProcessData();

  EndTime := Now;
  ElapsedMs := MilliSecondsBetween(EndTime, StartTime);

  WriteLn(Format('Temps d''ex√©cution : %d ms', [ElapsedMs]));
end;
```

### 4.3 Optimisation de l'alignement m√©moire

Pour SIMD, les donn√©es doivent √™tre align√©es en m√©moire :

```pascal
type
  // Alignement sur 32 octets pour AVX
  TAlignedArray = array[0..999] of Single align 32;

var
  Data: TAlignedArray;
```

### 4.4 Gestion multi-plateforme

Les diff√©rences entre Windows et Ubuntu :

```pascal
{$IFDEF WINDOWS}
  // Windows : utilise g√©n√©ralement plus de threads
  const OptimalThreads = 8;
{$ENDIF}

{$IFDEF LINUX}
  // Linux : peut b√©n√©ficier de plus de threads l√©gers
  const OptimalThreads = 16;
{$ENDIF}

// Ou d√©tecter automatiquement
uses
  {$IFDEF UNIX}BaseUnix{$ENDIF}
  {$IFDEF WINDOWS}Windows{$ENDIF};

function GetCPUCount: Integer;
begin
  {$IFDEF WINDOWS}
  Result := GetCPUCount; // Fonction syst√®me Windows
  {$ENDIF}

  {$IFDEF LINUX}
  Result := sysconf(_SC_NPROCESSORS_ONLN);
  {$ENDIF}
end;
```

---

## Conclusion

Le calcul parall√®le et la vectorisation sont des outils puissants pour acc√©l√©rer vos programmes FreePascal :

1. **Calcul parall√®le** : Utilise plusieurs c≈ìurs du processeur (gain x4 √† x16)
2. **Vectorisation** : Traite plusieurs donn√©es simultan√©ment (gain x4 √† x16)
3. **Combinaison** : Peut multiplier les performances par 50 ou plus !

**Points cl√©s √† retenir :**
- Utilisez MTProcs pour simplifier la parall√©lisation
- Laissez le compilateur vectoriser avec `-O3`
- Mesurez toujours les performances
- Attention aux race conditions
- V√©rifiez la compatibilit√© du processeur pour SIMD avanc√©

Avec ces techniques, vous pouvez transformer des calculs qui prenaient des heures en quelques minutes, tout en gardant un code relativement simple et portable entre Windows et Ubuntu !

‚è≠Ô∏è [Int√©gration avec R et Python](/16-traitement-donnees-calcul-scientifique/09-integration-r-python.md)
